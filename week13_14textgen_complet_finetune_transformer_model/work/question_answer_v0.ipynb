{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "01a3b9fc",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "01a3b9fc",
        "outputId": "59fdd207-b337-44c2-bc13-0c0031a49c4a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.40.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.4)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.22.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.12.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.2)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.11.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.2.2)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers datasets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7eLkVsiRo7Oq",
        "outputId": "ccd51b66-7761-4890-c067-06d58c66c255"
      },
      "id": "7eLkVsiRo7Oq",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.40.0)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (2.19.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.4)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.22.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.12.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.2)\n",
            "Requirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (14.0.2)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.0.3)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.4.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec[http]<=2024.3.1,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.5)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.11.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.2.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8tRqdd-No3rN"
      },
      "id": "8tRqdd-No3rN",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install accelerate -U"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y8F9v9Yvo0B3",
        "outputId": "c7fee132-cbd1-486c-cb40-2264ef27373d"
      },
      "id": "Y8F9v9Yvo0B3",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (0.29.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (24.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0.1)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.2.1+cu121)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.22.2)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.4.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.13.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.19.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.2.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->accelerate) (12.4.127)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (4.66.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2024.2.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3_7_N9TSoqIJ"
      },
      "id": "3_7_N9TSoqIJ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0cf8ozZMoL13"
      },
      "id": "0cf8ozZMoL13",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "4d7e71d9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4d7e71d9",
        "outputId": "658d3abf-2669-4008-a313-b0d4176cb8e3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "from datasets import load_dataset\n",
        "raw_datasets = load_dataset(\"squad\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "5123f124",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "5123f124",
        "outputId": "ed19150a-ff7b-4682-a277-37200746d3cf"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'University_of_Notre_Dame'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "raw_datasets[\"train\"][1][\"title\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "4137f590",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "id": "4137f590",
        "outputId": "17ddc442-cbe5-4cef-e72a-e83aaf4bf441"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Architecturally, the school has a Catholic character. Atop the Main Building\\'s gold dome is a golden statue of the Virgin Mary. Immediately in front of the Main Building and facing it, is a copper statue of Christ with arms upraised with the legend \"Venite Ad Me Omnes\". Next to the Main Building is the Basilica of the Sacred Heart. Immediately behind the basilica is the Grotto, a Marian place of prayer and reflection. It is a replica of the grotto at Lourdes, France where the Virgin Mary reputedly appeared to Saint Bernadette Soubirous in 1858. At the end of the main drive (and in a direct line that connects through 3 statues and the Gold Dome), is a simple, modern stone statue of Mary.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "raw_datasets[\"train\"][1][\"context\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "cde8d470",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "cde8d470",
        "outputId": "7f0baec4-abc2-4874-f4dd-0340dfcaeded"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'What is in front of the Notre Dame Main Building?'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "raw_datasets[\"train\"][1][\"question\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "6fea8342",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6fea8342",
        "outputId": "9b98df6a-e47a-4bbb-c487-16cf2570f32d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'text': ['a copper statue of Christ'], 'answer_start': [188]}"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "raw_datasets[\"train\"][1][\"answers\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "cb1b155d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cb1b155d",
        "outputId": "bba2aa0e-de38-41fe-9231-9ff476fd1b49"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['id', 'title', 'context', 'question', 'answers'],\n",
              "    num_rows: 0\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "#ensure you have only data with only 1 answer\n",
        "#next code of line checks (filters) if multiple answers occur\n",
        "raw_datasets[\"train\"].filter(lambda x: len(x[\"answers\"][\"text\"]) != 1)\n",
        "#The answer will show that there aren't any multiple answers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "cf957e61",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cf957e61",
        "outputId": "99813f99-a55f-4fd1-f43d-218b5b4c8af8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'text': ['Santa Clara, California',\n",
              "  \"Levi's Stadium\",\n",
              "  \"Levi's Stadium in the San Francisco Bay Area at Santa Clara, California.\"],\n",
              " 'answer_start': [403, 355, 355]}"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "raw_datasets[\"validation\"][2][\"answers\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "a0485bdc",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "id": "a0485bdc",
        "outputId": "b691972b-83d9-4b43-eee8-90c4090928b9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Super Bowl 50 was an American football game to determine the champion of the National Football League (NFL) for the 2015 season. The American Football Conference (AFC) champion Denver Broncos defeated the National Football Conference (NFC) champion Carolina Panthers 24–10 to earn their third Super Bowl title. The game was played on February 7, 2016, at Levi\\'s Stadium in the San Francisco Bay Area at Santa Clara, California. As this was the 50th Super Bowl, the league emphasized the \"golden anniversary\" with various gold-themed initiatives, as well as temporarily suspending the tradition of naming each Super Bowl game with Roman numerals (under which the game would have been known as \"Super Bowl L\"), so that the logo could prominently feature the Arabic numerals 50.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "raw_datasets[\"validation\"][2][\"context\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "18eda159",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "18eda159",
        "outputId": "7e83da5b-4dee-4562-b485-ec790b370ab7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Where did Super Bowl 50 take place?'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "raw_datasets[\"validation\"][2][\"question\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "44377e86",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "44377e86",
        "outputId": "90e769ab-b446-443a-86c5-a8a7604700fb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['__class__',\n",
              " '__class_getitem__',\n",
              " '__contains__',\n",
              " '__delattr__',\n",
              " '__delitem__',\n",
              " '__dict__',\n",
              " '__dir__',\n",
              " '__doc__',\n",
              " '__enter__',\n",
              " '__eq__',\n",
              " '__exit__',\n",
              " '__format__',\n",
              " '__ge__',\n",
              " '__getattribute__',\n",
              " '__getitem__',\n",
              " '__gt__',\n",
              " '__hash__',\n",
              " '__init__',\n",
              " '__init_subclass__',\n",
              " '__ior__',\n",
              " '__iter__',\n",
              " '__le__',\n",
              " '__len__',\n",
              " '__lt__',\n",
              " '__module__',\n",
              " '__ne__',\n",
              " '__new__',\n",
              " '__or__',\n",
              " '__reduce__',\n",
              " '__reduce_ex__',\n",
              " '__repr__',\n",
              " '__reversed__',\n",
              " '__ror__',\n",
              " '__setattr__',\n",
              " '__setitem__',\n",
              " '__sizeof__',\n",
              " '__str__',\n",
              " '__subclasshook__',\n",
              " '__weakref__',\n",
              " '_check_values_features',\n",
              " '_check_values_type',\n",
              " 'align_labels_with_mapping',\n",
              " 'cache_files',\n",
              " 'cast',\n",
              " 'cast_column',\n",
              " 'class_encode_column',\n",
              " 'cleanup_cache_files',\n",
              " 'clear',\n",
              " 'column_names',\n",
              " 'copy',\n",
              " 'data',\n",
              " 'filter',\n",
              " 'flatten',\n",
              " 'flatten_indices',\n",
              " 'formatted_as',\n",
              " 'from_csv',\n",
              " 'from_json',\n",
              " 'from_parquet',\n",
              " 'from_text',\n",
              " 'fromkeys',\n",
              " 'get',\n",
              " 'items',\n",
              " 'keys',\n",
              " 'load_from_disk',\n",
              " 'map',\n",
              " 'num_columns',\n",
              " 'num_rows',\n",
              " 'pop',\n",
              " 'popitem',\n",
              " 'prepare_for_task',\n",
              " 'push_to_hub',\n",
              " 'remove_columns',\n",
              " 'rename_column',\n",
              " 'rename_columns',\n",
              " 'reset_format',\n",
              " 'save_to_disk',\n",
              " 'select_columns',\n",
              " 'set_format',\n",
              " 'set_transform',\n",
              " 'setdefault',\n",
              " 'shape',\n",
              " 'shuffle',\n",
              " 'sort',\n",
              " 'unique',\n",
              " 'update',\n",
              " 'values',\n",
              " 'with_format',\n",
              " 'with_transform']"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "dir(raw_datasets)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "af88ffe0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "af88ffe0",
        "outputId": "f9731537-0aea-4786-9af6-3fe1f0549870"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['id', 'title', 'context', 'question', 'answers'],\n",
              "        num_rows: 87599\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['id', 'title', 'context', 'question', 'answers'],\n",
              "        num_rows: 10570\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "raw_datasets\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "a9e80882",
      "metadata": {
        "scrolled": false,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a9e80882",
        "outputId": "c092c2a0-24d7-46c8-e543-aa67bdc955dc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'id': '5733be284776f41900661182',\n",
              " 'title': 'University_of_Notre_Dame',\n",
              " 'context': 'Architecturally, the school has a Catholic character. Atop the Main Building\\'s gold dome is a golden statue of the Virgin Mary. Immediately in front of the Main Building and facing it, is a copper statue of Christ with arms upraised with the legend \"Venite Ad Me Omnes\". Next to the Main Building is the Basilica of the Sacred Heart. Immediately behind the basilica is the Grotto, a Marian place of prayer and reflection. It is a replica of the grotto at Lourdes, France where the Virgin Mary reputedly appeared to Saint Bernadette Soubirous in 1858. At the end of the main drive (and in a direct line that connects through 3 statues and the Gold Dome), is a simple, modern stone statue of Mary.',\n",
              " 'question': 'To whom did the Virgin Mary allegedly appear in 1858 in Lourdes France?',\n",
              " 'answers': {'text': ['Saint Bernadette Soubirous'], 'answer_start': [515]}}"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "raw_datasets['train'][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "fbdf3655",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fbdf3655",
        "outputId": "0b8c6d1e-855d-42a2-8466-a51bc320a218"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "datasets.dataset_dict.DatasetDict"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "type(raw_datasets)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "0a88e78a",
      "metadata": {
        "id": "0a88e78a"
      },
      "outputs": [],
      "source": [
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "714de42f",
      "metadata": {
        "id": "714de42f"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "cf628a72",
      "metadata": {
        "id": "cf628a72"
      },
      "outputs": [],
      "source": [
        "model_checkpoint = \"distilbert-base-cased\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "3dd7b691",
      "metadata": {
        "id": "3dd7b691"
      },
      "outputs": [],
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "c70a3afb",
      "metadata": {
        "id": "c70a3afb"
      },
      "outputs": [],
      "source": [
        "context = raw_datasets['train'][1]['context']\n",
        "question = raw_datasets['train'][1]['question']\n",
        "\n",
        "inputs = tokenizer(question, context)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.decode(inputs['input_ids'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "id": "WrbaTWqRgqF_",
        "outputId": "442c2eac-1e12-4df5-8755-3a1cca517ba9"
      },
      "id": "WrbaTWqRgqF_",
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'[CLS] What is in front of the Notre Dame Main Building? [SEP] Architecturally, the school has a Catholic character. Atop the Main Building\\'s gold dome is a golden statue of the Virgin Mary. Immediately in front of the Main Building and facing it, is a copper statue of Christ with arms upraised with the legend \" Venite Ad Me Omnes \". Next to the Main Building is the Basilica of the Sacred Heart. Immediately behind the basilica is the Grotto, a Marian place of prayer and reflection. It is a replica of the grotto at Lourdes, France where the Virgin Mary reputedly appeared to Saint Bernadette Soubirous in 1858. At the end of the main drive ( and in a direct line that connects through 3 statues and the Gold Dome ), is a simple, modern stone statue of Mary. [SEP]'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "409932e0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "409932e0",
        "outputId": "34030baa-164d-4a66-b86a-2e35c5daf47d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': [101, 1327, 1110, 1107, 1524, 1104, 1103, 10360, 8022, 4304, 4334, 136, 102, 22182, 1193, 117, 1103, 1278, 1144, 170, 2336, 1959, 119, 1335, 4184, 1103, 4304, 4334, 112, 188, 2284, 10945, 1110, 170, 5404, 5921, 1104, 1103, 6567, 2090, 119, 13301, 1107, 1524, 1104, 1103, 4304, 4334, 1105, 4749, 1122, 117, 1110, 170, 7335, 5921, 1104, 4028, 1114, 1739, 1146, 14089, 5591, 1114, 1103, 7051, 107, 159, 21462, 1566, 24930, 2508, 152, 1306, 3965, 107, 119, 5893, 1106, 1103, 4304, 4334, 1110, 1103, 19349, 1104, 1103, 11373, 4641, 119, 13301, 1481, 1103, 171, 17506, 9538, 1110, 1103, 144, 10595, 2430, 117, 170, 14789, 1282, 1104, 8070, 1105, 9284, 119, 1135, 1110, 170, 16498, 1104, 1103, 176, 10595, 2430, 1120, 10111, 20500, 117, 1699, 1187, 1103, 6567, 2090, 25153, 1193, 1691, 1106, 2216, 17666, 6397, 3786, 1573, 25422, 13149, 1107, 8109, 119, 1335, 1103, 1322, 1104, 1103, 1514, 2797, 113, 1105, 1107, 170, 2904, 1413, 1115, 8200, 1194, 124, 11739, 1105, 1103, 3487, 17917, 114, 117, 1110, 170, 3014, 117, 2030, 2576, 5921, 1104, 2090, 119, 102], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "inputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "d22aa7c1",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 220
        },
        "id": "d22aa7c1",
        "outputId": "3eab4933-bb90-4da8-f3e9-58e1628981ff"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "transformers.tokenization_utils_base.BatchEncoding"
            ],
            "text/html": [
              "<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n",
              "      pre.function-repr-contents {\n",
              "        overflow-x: auto;\n",
              "        padding: 8px 12px;\n",
              "        max-height: 500px;\n",
              "      }\n",
              "\n",
              "      pre.function-repr-contents.function-repr-contents-collapsed {\n",
              "        cursor: pointer;\n",
              "        max-height: 100px;\n",
              "      }\n",
              "    </style>\n",
              "    <pre style=\"white-space: initial; background:\n",
              "         var(--colab-secondary-surface-color); padding: 8px 12px;\n",
              "         border-bottom: 1px solid var(--colab-border-color);\"><b>transformers.tokenization_utils_base.BatchEncoding</b><br/>def __init__(data: Optional[Dict[str, Any]]=None, encoding: Optional[Union[EncodingFast, Sequence[EncodingFast]]]=None, tensor_type: Union[None, str, TensorType]=None, prepend_batch_axis: bool=False, n_sequences: Optional[int]=None)</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py</a>Holds the output of the [`~tokenization_utils_base.PreTrainedTokenizerBase.__call__`],\n",
              "[`~tokenization_utils_base.PreTrainedTokenizerBase.encode_plus`] and\n",
              "[`~tokenization_utils_base.PreTrainedTokenizerBase.batch_encode_plus`] methods (tokens, attention_masks, etc).\n",
              "\n",
              "This class is derived from a python dictionary and can be used as a dictionary. In addition, this class exposes\n",
              "utility methods to map from word/character space to token space.\n",
              "\n",
              "Args:\n",
              "    data (`dict`, *optional*):\n",
              "        Dictionary of lists/arrays/tensors returned by the `__call__`/`encode_plus`/`batch_encode_plus` methods\n",
              "        (&#x27;input_ids&#x27;, &#x27;attention_mask&#x27;, etc.).\n",
              "    encoding (`tokenizers.Encoding` or `Sequence[tokenizers.Encoding]`, *optional*):\n",
              "        If the tokenizer is a fast tokenizer which outputs additional information like mapping from word/character\n",
              "        space to token space the `tokenizers.Encoding` instance or list of instance (for batches) hold this\n",
              "        information.\n",
              "    tensor_type (`Union[None, str, TensorType]`, *optional*):\n",
              "        You can give a tensor_type here to convert the lists of integers in PyTorch/TensorFlow/Numpy Tensors at\n",
              "        initialization.\n",
              "    prepend_batch_axis (`bool`, *optional*, defaults to `False`):\n",
              "        Whether or not to add a batch axis when converting to tensors (see `tensor_type` above).\n",
              "    n_sequences (`Optional[int]`, *optional*):\n",
              "        You can give a tensor_type here to convert the lists of integers in PyTorch/TensorFlow/Numpy Tensors at\n",
              "        initialization.</pre>\n",
              "      <script>\n",
              "      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n",
              "        for (const element of document.querySelectorAll('.filepath')) {\n",
              "          element.style.display = 'block'\n",
              "          element.onclick = (event) => {\n",
              "            event.preventDefault();\n",
              "            event.stopPropagation();\n",
              "            google.colab.files.view(element.textContent, 177);\n",
              "          };\n",
              "        }\n",
              "      }\n",
              "      for (const element of document.querySelectorAll('.function-repr-contents')) {\n",
              "        element.onclick = (event) => {\n",
              "          event.preventDefault();\n",
              "          event.stopPropagation();\n",
              "          element.classList.toggle('function-repr-contents-collapsed');\n",
              "        };\n",
              "      }\n",
              "      </script>\n",
              "      </div>"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "type(inputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "06c2f8c8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "06c2f8c8",
        "outputId": "595bdfe2-f17a-4a3b-ac06-7bfc5b016231"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': [101, 1327, 1110, 1107, 1524, 1104, 1103, 10360, 8022, 4304, 4334, 136, 102, 22182, 1193, 117, 1103, 1278, 1144, 170, 2336, 1959, 119, 1335, 4184, 1103, 4304, 4334, 112, 188, 2284, 10945, 1110, 170, 5404, 5921, 1104, 1103, 6567, 2090, 119, 13301, 1107, 1524, 1104, 1103, 4304, 4334, 1105, 4749, 1122, 117, 1110, 170, 7335, 5921, 1104, 4028, 1114, 1739, 1146, 14089, 5591, 1114, 1103, 7051, 107, 159, 21462, 1566, 24930, 2508, 152, 1306, 3965, 107, 119, 5893, 1106, 1103, 4304, 4334, 1110, 1103, 19349, 1104, 1103, 11373, 4641, 119, 13301, 1481, 1103, 171, 17506, 9538, 1110, 1103, 144, 10595, 2430, 117, 170, 14789, 1282, 1104, 8070, 1105, 9284, 119, 1135, 1110, 170, 16498, 1104, 1103, 176, 10595, 2430, 1120, 10111, 20500, 117, 1699, 1187, 1103, 6567, 2090, 25153, 1193, 1691, 1106, 2216, 17666, 6397, 3786, 1573, 25422, 13149, 1107, 8109, 119, 1335, 1103, 1322, 1104, 1103, 1514, 2797, 113, 1105, 1107, 170, 2904, 1413, 1115, 8200, 1194, 124, 11739, 1105, 1103, 3487, 17917, 114, 117, 1110, 170, 3014, 117, 2030, 2576, 5921, 1104, 2090, 119, 102], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "inputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "442a5b56",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "442a5b56",
        "outputId": "7a6e0b05-24ee-438e-87c5-5206a66851f8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CLS] What is in front of the Notre Dame Main Building? [SEP] Architecturally, the school has a Catholic character. Atop the Main Building's gold dome is a golden statue of the Virgin Mary. Immediately in front of the Main Building and facing it, is a copper statue of Christ with arms upraised with the legend \" Venite Ad Me Omnes \". Next to the Main Building is the Basilica of the Sacred Heart. Immediately behind the basilica is the G [SEP]\n",
            "[CLS] What is in front of the Notre Dame Main Building? [SEP] facing it, is a copper statue of Christ with arms upraised with the legend \" Venite Ad Me Omnes \". Next to the Main Building is the Basilica of the Sacred Heart. Immediately behind the basilica is the Grotto, a Marian place of prayer and reflection. It is a replica of the grotto at Lourdes, France where the Virgin Mary reputedly appeared to Saint Bernade [SEP]\n",
            "[CLS] What is in front of the Notre Dame Main Building? [SEP] of the Sacred Heart. Immediately behind the basilica is the Grotto, a Marian place of prayer and reflection. It is a replica of the grotto at Lourdes, France where the Virgin Mary reputedly appeared to Saint Bernadette Soubirous in 1858. At the end of the main drive ( and in a direct line that connects through 3 statues and the Gold Dome ), is a simple, modern [SEP]\n",
            "[CLS] What is in front of the Notre Dame Main Building? [SEP]rdes, France where the Virgin Mary reputedly appeared to Saint Bernadette Soubirous in 1858. At the end of the main drive ( and in a direct line that connects through 3 statues and the Gold Dome ), is a simple, modern stone statue of Mary. [SEP]\n"
          ]
        }
      ],
      "source": [
        "#What if the context is really long?\n",
        "#split it into multiple samples\n",
        "\n",
        "inputs = tokenizer(\n",
        "    question,\n",
        "    context,\n",
        "    max_length=100,\n",
        "    truncation = \"only_second\",\n",
        "    stride=50,\n",
        "    return_overflowing_tokens=True,\n",
        ")\n",
        "\n",
        "for ids in inputs[\"input_ids\"]:\n",
        "    print(tokenizer.decode(ids))\n",
        "\n",
        "#stride = number of allowed overlapping tokens\n",
        "#max_length: 100, after 100 tokens there is a truncation\n",
        "#truncation : only_second : we will only truncate the context"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "138bf53a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "138bf53a",
        "outputId": "a2488937-09fc-4325-ede3-d9c13ac443e0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['input_ids', 'attention_mask', 'overflow_to_sample_mapping'])"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "inputs.keys()\n",
        "#you can see there is an EXTRA KEY NOW : overflow_to_sample_mapping"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "3db499d1",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3db499d1",
        "outputId": "e2c14e1a-6c26-4a1d-841c-7f703290b350"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': [[101, 1327, 1110, 1107, 1524, 1104, 1103, 10360, 8022, 4304, 4334, 136, 102, 22182, 1193, 117, 1103, 1278, 1144, 170, 2336, 1959, 119, 1335, 4184, 1103, 4304, 4334, 112, 188, 2284, 10945, 1110, 170, 5404, 5921, 1104, 1103, 6567, 2090, 119, 13301, 1107, 1524, 1104, 1103, 4304, 4334, 1105, 4749, 1122, 117, 1110, 170, 7335, 5921, 1104, 4028, 1114, 1739, 1146, 14089, 5591, 1114, 1103, 7051, 107, 159, 21462, 1566, 24930, 2508, 152, 1306, 3965, 107, 119, 5893, 1106, 1103, 4304, 4334, 1110, 1103, 19349, 1104, 1103, 11373, 4641, 119, 13301, 1481, 1103, 171, 17506, 9538, 1110, 1103, 144, 102], [101, 1327, 1110, 1107, 1524, 1104, 1103, 10360, 8022, 4304, 4334, 136, 102, 4749, 1122, 117, 1110, 170, 7335, 5921, 1104, 4028, 1114, 1739, 1146, 14089, 5591, 1114, 1103, 7051, 107, 159, 21462, 1566, 24930, 2508, 152, 1306, 3965, 107, 119, 5893, 1106, 1103, 4304, 4334, 1110, 1103, 19349, 1104, 1103, 11373, 4641, 119, 13301, 1481, 1103, 171, 17506, 9538, 1110, 1103, 144, 10595, 2430, 117, 170, 14789, 1282, 1104, 8070, 1105, 9284, 119, 1135, 1110, 170, 16498, 1104, 1103, 176, 10595, 2430, 1120, 10111, 20500, 117, 1699, 1187, 1103, 6567, 2090, 25153, 1193, 1691, 1106, 2216, 17666, 6397, 102], [101, 1327, 1110, 1107, 1524, 1104, 1103, 10360, 8022, 4304, 4334, 136, 102, 1104, 1103, 11373, 4641, 119, 13301, 1481, 1103, 171, 17506, 9538, 1110, 1103, 144, 10595, 2430, 117, 170, 14789, 1282, 1104, 8070, 1105, 9284, 119, 1135, 1110, 170, 16498, 1104, 1103, 176, 10595, 2430, 1120, 10111, 20500, 117, 1699, 1187, 1103, 6567, 2090, 25153, 1193, 1691, 1106, 2216, 17666, 6397, 3786, 1573, 25422, 13149, 1107, 8109, 119, 1335, 1103, 1322, 1104, 1103, 1514, 2797, 113, 1105, 1107, 170, 2904, 1413, 1115, 8200, 1194, 124, 11739, 1105, 1103, 3487, 17917, 114, 117, 1110, 170, 3014, 117, 2030, 102], [101, 1327, 1110, 1107, 1524, 1104, 1103, 10360, 8022, 4304, 4334, 136, 102, 20500, 117, 1699, 1187, 1103, 6567, 2090, 25153, 1193, 1691, 1106, 2216, 17666, 6397, 3786, 1573, 25422, 13149, 1107, 8109, 119, 1335, 1103, 1322, 1104, 1103, 1514, 2797, 113, 1105, 1107, 170, 2904, 1413, 1115, 8200, 1194, 124, 11739, 1105, 1103, 3487, 17917, 114, 117, 1110, 170, 3014, 117, 2030, 2576, 5921, 1104, 2090, 119, 102]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], 'overflow_to_sample_mapping': [0, 0, 0, 0]}"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "inputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "105c7945",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "105c7945",
        "outputId": "eca04ab1-61fc-4c65-dc48-25549820eb82"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0, 0, 0, 0]"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "inputs['overflow_to_sample_mapping']\n",
        "#the 4 x  zero's are in fact the sample index numbers\n",
        "#we used only 1 sample here, so the 4 split context refer to sample 0\n",
        "#We explain this with another example in the cells below where we use more than 1 sample:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "2f2b2ac5",
      "metadata": {
        "scrolled": false,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2f2b2ac5",
        "outputId": "58c60906-b467-4396-acda-734b30a3de25"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0, 0, 0, 0, 1, 1, 1, 1, 2, 2, 2, 2]"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ],
      "source": [
        "#What if the context is really long?\n",
        "#split it into multiple samples\n",
        "\n",
        "inputs = tokenizer(\n",
        "    raw_datasets['train'][:3]['question'],\n",
        "    raw_datasets['train'][:3]['context'],\n",
        "    max_length=100,\n",
        "    truncation = \"only_second\",\n",
        "    stride=50,\n",
        "    return_overflowing_tokens=True,\n",
        "    return_offsets_mapping=True\n",
        ")\n",
        "\n",
        "inputs['overflow_to_sample_mapping']\n",
        "\n",
        "#stride = number of allowed overlapping tokens\n",
        "#max_length: 100, after 100 tokens there is a truncation\n",
        "#truncation : only_second : we will only truncate the context\n",
        "\n",
        "#extra line in tokenizer:\n",
        "#return_offsets_mapping=True\n",
        "\n",
        "#below are duplicated contexts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "e6e1ad0b",
      "metadata": {
        "scrolled": false,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e6e1ad0b",
        "outputId": "f5902075-1cd7-43a9-8f0e-c84d3582ff22"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': [[101, 1706, 2292, 1225, 1103, 6567, 2090, 9273, 2845, 1107, 8109, 1107, 10111, 20500, 1699, 136, 102, 22182, 1193, 117, 1103, 1278, 1144, 170, 2336, 1959, 119, 1335, 4184, 1103, 4304, 4334, 112, 188, 2284, 10945, 1110, 170, 5404, 5921, 1104, 1103, 6567, 2090, 119, 13301, 1107, 1524, 1104, 1103, 4304, 4334, 1105, 4749, 1122, 117, 1110, 170, 7335, 5921, 1104, 4028, 1114, 1739, 1146, 14089, 5591, 1114, 1103, 7051, 107, 159, 21462, 1566, 24930, 2508, 152, 1306, 3965, 107, 119, 5893, 1106, 1103, 4304, 4334, 1110, 1103, 19349, 1104, 1103, 11373, 4641, 119, 13301, 1481, 1103, 171, 17506, 102], [101, 1706, 2292, 1225, 1103, 6567, 2090, 9273, 2845, 1107, 8109, 1107, 10111, 20500, 1699, 136, 102, 1103, 4304, 4334, 1105, 4749, 1122, 117, 1110, 170, 7335, 5921, 1104, 4028, 1114, 1739, 1146, 14089, 5591, 1114, 1103, 7051, 107, 159, 21462, 1566, 24930, 2508, 152, 1306, 3965, 107, 119, 5893, 1106, 1103, 4304, 4334, 1110, 1103, 19349, 1104, 1103, 11373, 4641, 119, 13301, 1481, 1103, 171, 17506, 9538, 1110, 1103, 144, 10595, 2430, 117, 170, 14789, 1282, 1104, 8070, 1105, 9284, 119, 1135, 1110, 170, 16498, 1104, 1103, 176, 10595, 2430, 1120, 10111, 20500, 117, 1699, 1187, 1103, 6567, 102], [101, 1706, 2292, 1225, 1103, 6567, 2090, 9273, 2845, 1107, 8109, 1107, 10111, 20500, 1699, 136, 102, 5893, 1106, 1103, 4304, 4334, 1110, 1103, 19349, 1104, 1103, 11373, 4641, 119, 13301, 1481, 1103, 171, 17506, 9538, 1110, 1103, 144, 10595, 2430, 117, 170, 14789, 1282, 1104, 8070, 1105, 9284, 119, 1135, 1110, 170, 16498, 1104, 1103, 176, 10595, 2430, 1120, 10111, 20500, 117, 1699, 1187, 1103, 6567, 2090, 25153, 1193, 1691, 1106, 2216, 17666, 6397, 3786, 1573, 25422, 13149, 1107, 8109, 119, 1335, 1103, 1322, 1104, 1103, 1514, 2797, 113, 1105, 1107, 170, 2904, 1413, 1115, 8200, 1194, 124, 102], [101, 1706, 2292, 1225, 1103, 6567, 2090, 9273, 2845, 1107, 8109, 1107, 10111, 20500, 1699, 136, 102, 119, 1135, 1110, 170, 16498, 1104, 1103, 176, 10595, 2430, 1120, 10111, 20500, 117, 1699, 1187, 1103, 6567, 2090, 25153, 1193, 1691, 1106, 2216, 17666, 6397, 3786, 1573, 25422, 13149, 1107, 8109, 119, 1335, 1103, 1322, 1104, 1103, 1514, 2797, 113, 1105, 1107, 170, 2904, 1413, 1115, 8200, 1194, 124, 11739, 1105, 1103, 3487, 17917, 114, 117, 1110, 170, 3014, 117, 2030, 2576, 5921, 1104, 2090, 119, 102], [101, 1327, 1110, 1107, 1524, 1104, 1103, 10360, 8022, 4304, 4334, 136, 102, 22182, 1193, 117, 1103, 1278, 1144, 170, 2336, 1959, 119, 1335, 4184, 1103, 4304, 4334, 112, 188, 2284, 10945, 1110, 170, 5404, 5921, 1104, 1103, 6567, 2090, 119, 13301, 1107, 1524, 1104, 1103, 4304, 4334, 1105, 4749, 1122, 117, 1110, 170, 7335, 5921, 1104, 4028, 1114, 1739, 1146, 14089, 5591, 1114, 1103, 7051, 107, 159, 21462, 1566, 24930, 2508, 152, 1306, 3965, 107, 119, 5893, 1106, 1103, 4304, 4334, 1110, 1103, 19349, 1104, 1103, 11373, 4641, 119, 13301, 1481, 1103, 171, 17506, 9538, 1110, 1103, 144, 102], [101, 1327, 1110, 1107, 1524, 1104, 1103, 10360, 8022, 4304, 4334, 136, 102, 4749, 1122, 117, 1110, 170, 7335, 5921, 1104, 4028, 1114, 1739, 1146, 14089, 5591, 1114, 1103, 7051, 107, 159, 21462, 1566, 24930, 2508, 152, 1306, 3965, 107, 119, 5893, 1106, 1103, 4304, 4334, 1110, 1103, 19349, 1104, 1103, 11373, 4641, 119, 13301, 1481, 1103, 171, 17506, 9538, 1110, 1103, 144, 10595, 2430, 117, 170, 14789, 1282, 1104, 8070, 1105, 9284, 119, 1135, 1110, 170, 16498, 1104, 1103, 176, 10595, 2430, 1120, 10111, 20500, 117, 1699, 1187, 1103, 6567, 2090, 25153, 1193, 1691, 1106, 2216, 17666, 6397, 102], [101, 1327, 1110, 1107, 1524, 1104, 1103, 10360, 8022, 4304, 4334, 136, 102, 1104, 1103, 11373, 4641, 119, 13301, 1481, 1103, 171, 17506, 9538, 1110, 1103, 144, 10595, 2430, 117, 170, 14789, 1282, 1104, 8070, 1105, 9284, 119, 1135, 1110, 170, 16498, 1104, 1103, 176, 10595, 2430, 1120, 10111, 20500, 117, 1699, 1187, 1103, 6567, 2090, 25153, 1193, 1691, 1106, 2216, 17666, 6397, 3786, 1573, 25422, 13149, 1107, 8109, 119, 1335, 1103, 1322, 1104, 1103, 1514, 2797, 113, 1105, 1107, 170, 2904, 1413, 1115, 8200, 1194, 124, 11739, 1105, 1103, 3487, 17917, 114, 117, 1110, 170, 3014, 117, 2030, 102], [101, 1327, 1110, 1107, 1524, 1104, 1103, 10360, 8022, 4304, 4334, 136, 102, 20500, 117, 1699, 1187, 1103, 6567, 2090, 25153, 1193, 1691, 1106, 2216, 17666, 6397, 3786, 1573, 25422, 13149, 1107, 8109, 119, 1335, 1103, 1322, 1104, 1103, 1514, 2797, 113, 1105, 1107, 170, 2904, 1413, 1115, 8200, 1194, 124, 11739, 1105, 1103, 3487, 17917, 114, 117, 1110, 170, 3014, 117, 2030, 2576, 5921, 1104, 2090, 119, 102], [101, 1109, 19349, 1104, 1103, 11373, 1762, 1120, 10360, 8022, 1110, 3148, 1106, 1134, 2401, 136, 102, 22182, 1193, 117, 1103, 1278, 1144, 170, 2336, 1959, 119, 1335, 4184, 1103, 4304, 4334, 112, 188, 2284, 10945, 1110, 170, 5404, 5921, 1104, 1103, 6567, 2090, 119, 13301, 1107, 1524, 1104, 1103, 4304, 4334, 1105, 4749, 1122, 117, 1110, 170, 7335, 5921, 1104, 4028, 1114, 1739, 1146, 14089, 5591, 1114, 1103, 7051, 107, 159, 21462, 1566, 24930, 2508, 152, 1306, 3965, 107, 119, 5893, 1106, 1103, 4304, 4334, 1110, 1103, 19349, 1104, 1103, 11373, 4641, 119, 13301, 1481, 1103, 171, 17506, 102], [101, 1109, 19349, 1104, 1103, 11373, 1762, 1120, 10360, 8022, 1110, 3148, 1106, 1134, 2401, 136, 102, 1103, 4304, 4334, 1105, 4749, 1122, 117, 1110, 170, 7335, 5921, 1104, 4028, 1114, 1739, 1146, 14089, 5591, 1114, 1103, 7051, 107, 159, 21462, 1566, 24930, 2508, 152, 1306, 3965, 107, 119, 5893, 1106, 1103, 4304, 4334, 1110, 1103, 19349, 1104, 1103, 11373, 4641, 119, 13301, 1481, 1103, 171, 17506, 9538, 1110, 1103, 144, 10595, 2430, 117, 170, 14789, 1282, 1104, 8070, 1105, 9284, 119, 1135, 1110, 170, 16498, 1104, 1103, 176, 10595, 2430, 1120, 10111, 20500, 117, 1699, 1187, 1103, 6567, 102], [101, 1109, 19349, 1104, 1103, 11373, 1762, 1120, 10360, 8022, 1110, 3148, 1106, 1134, 2401, 136, 102, 5893, 1106, 1103, 4304, 4334, 1110, 1103, 19349, 1104, 1103, 11373, 4641, 119, 13301, 1481, 1103, 171, 17506, 9538, 1110, 1103, 144, 10595, 2430, 117, 170, 14789, 1282, 1104, 8070, 1105, 9284, 119, 1135, 1110, 170, 16498, 1104, 1103, 176, 10595, 2430, 1120, 10111, 20500, 117, 1699, 1187, 1103, 6567, 2090, 25153, 1193, 1691, 1106, 2216, 17666, 6397, 3786, 1573, 25422, 13149, 1107, 8109, 119, 1335, 1103, 1322, 1104, 1103, 1514, 2797, 113, 1105, 1107, 170, 2904, 1413, 1115, 8200, 1194, 124, 102], [101, 1109, 19349, 1104, 1103, 11373, 1762, 1120, 10360, 8022, 1110, 3148, 1106, 1134, 2401, 136, 102, 119, 1135, 1110, 170, 16498, 1104, 1103, 176, 10595, 2430, 1120, 10111, 20500, 117, 1699, 1187, 1103, 6567, 2090, 25153, 1193, 1691, 1106, 2216, 17666, 6397, 3786, 1573, 25422, 13149, 1107, 8109, 119, 1335, 1103, 1322, 1104, 1103, 1514, 2797, 113, 1105, 1107, 170, 2904, 1413, 1115, 8200, 1194, 124, 11739, 1105, 1103, 3487, 17917, 114, 117, 1110, 170, 3014, 117, 2030, 2576, 5921, 1104, 2090, 119, 102]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], 'offset_mapping': [[(0, 0), (0, 2), (3, 7), (8, 11), (12, 15), (16, 22), (23, 27), (28, 37), (38, 44), (45, 47), (48, 52), (53, 55), (56, 59), (59, 63), (64, 70), (70, 71), (0, 0), (0, 13), (13, 15), (15, 16), (17, 20), (21, 27), (28, 31), (32, 33), (34, 42), (43, 52), (52, 53), (54, 56), (56, 58), (59, 62), (63, 67), (68, 76), (76, 77), (77, 78), (79, 83), (84, 88), (89, 91), (92, 93), (94, 100), (101, 107), (108, 110), (111, 114), (115, 121), (122, 126), (126, 127), (128, 139), (140, 142), (143, 148), (149, 151), (152, 155), (156, 160), (161, 169), (170, 173), (174, 180), (181, 183), (183, 184), (185, 187), (188, 189), (190, 196), (197, 203), (204, 206), (207, 213), (214, 218), (219, 223), (224, 226), (226, 229), (229, 232), (233, 237), (238, 241), (242, 248), (249, 250), (250, 251), (251, 254), (254, 256), (257, 259), (260, 262), (263, 264), (264, 265), (265, 268), (268, 269), (269, 270), (271, 275), (276, 278), (279, 282), (283, 287), (288, 296), (297, 299), (300, 303), (304, 312), (313, 315), (316, 319), (320, 326), (327, 332), (332, 333), (334, 345), (346, 352), (353, 356), (357, 358), (358, 361), (0, 0)], [(0, 0), (0, 2), (3, 7), (8, 11), (12, 15), (16, 22), (23, 27), (28, 37), (38, 44), (45, 47), (48, 52), (53, 55), (56, 59), (59, 63), (64, 70), (70, 71), (0, 0), (152, 155), (156, 160), (161, 169), (170, 173), (174, 180), (181, 183), (183, 184), (185, 187), (188, 189), (190, 196), (197, 203), (204, 206), (207, 213), (214, 218), (219, 223), (224, 226), (226, 229), (229, 232), (233, 237), (238, 241), (242, 248), (249, 250), (250, 251), (251, 254), (254, 256), (257, 259), (260, 262), (263, 264), (264, 265), (265, 268), (268, 269), (269, 270), (271, 275), (276, 278), (279, 282), (283, 287), (288, 296), (297, 299), (300, 303), (304, 312), (313, 315), (316, 319), (320, 326), (327, 332), (332, 333), (334, 345), (346, 352), (353, 356), (357, 358), (358, 361), (361, 365), (366, 368), (369, 372), (373, 374), (374, 377), (377, 379), (379, 380), (381, 382), (383, 389), (390, 395), (396, 398), (399, 405), (406, 409), (410, 420), (420, 421), (422, 424), (425, 427), (428, 429), (430, 437), (438, 440), (441, 444), (445, 446), (446, 449), (449, 451), (452, 454), (455, 458), (458, 462), (462, 463), (464, 470), (471, 476), (477, 480), (481, 487), (0, 0)], [(0, 0), (0, 2), (3, 7), (8, 11), (12, 15), (16, 22), (23, 27), (28, 37), (38, 44), (45, 47), (48, 52), (53, 55), (56, 59), (59, 63), (64, 70), (70, 71), (0, 0), (271, 275), (276, 278), (279, 282), (283, 287), (288, 296), (297, 299), (300, 303), (304, 312), (313, 315), (316, 319), (320, 326), (327, 332), (332, 333), (334, 345), (346, 352), (353, 356), (357, 358), (358, 361), (361, 365), (366, 368), (369, 372), (373, 374), (374, 377), (377, 379), (379, 380), (381, 382), (383, 389), (390, 395), (396, 398), (399, 405), (406, 409), (410, 420), (420, 421), (422, 424), (425, 427), (428, 429), (430, 437), (438, 440), (441, 444), (445, 446), (446, 449), (449, 451), (452, 454), (455, 458), (458, 462), (462, 463), (464, 470), (471, 476), (477, 480), (481, 487), (488, 492), (493, 500), (500, 502), (503, 511), (512, 514), (515, 520), (521, 525), (525, 528), (528, 531), (532, 534), (534, 537), (537, 541), (542, 544), (545, 549), (549, 550), (551, 553), (554, 557), (558, 561), (562, 564), (565, 568), (569, 573), (574, 579), (580, 581), (581, 584), (585, 587), (588, 589), (590, 596), (597, 601), (602, 606), (607, 615), (616, 623), (624, 625), (0, 0)], [(0, 0), (0, 2), (3, 7), (8, 11), (12, 15), (16, 22), (23, 27), (28, 37), (38, 44), (45, 47), (48, 52), (53, 55), (56, 59), (59, 63), (64, 70), (70, 71), (0, 0), (420, 421), (422, 424), (425, 427), (428, 429), (430, 437), (438, 440), (441, 444), (445, 446), (446, 449), (449, 451), (452, 454), (455, 458), (458, 462), (462, 463), (464, 470), (471, 476), (477, 480), (481, 487), (488, 492), (493, 500), (500, 502), (503, 511), (512, 514), (515, 520), (521, 525), (525, 528), (528, 531), (532, 534), (534, 537), (537, 541), (542, 544), (545, 549), (549, 550), (551, 553), (554, 557), (558, 561), (562, 564), (565, 568), (569, 573), (574, 579), (580, 581), (581, 584), (585, 587), (588, 589), (590, 596), (597, 601), (602, 606), (607, 615), (616, 623), (624, 625), (626, 633), (634, 637), (638, 641), (642, 646), (647, 651), (651, 652), (652, 653), (654, 656), (657, 658), (659, 665), (665, 666), (667, 673), (674, 679), (680, 686), (687, 689), (690, 694), (694, 695), (0, 0)], [(0, 0), (0, 4), (5, 7), (8, 10), (11, 16), (17, 19), (20, 23), (24, 29), (30, 34), (35, 39), (40, 48), (48, 49), (0, 0), (0, 13), (13, 15), (15, 16), (17, 20), (21, 27), (28, 31), (32, 33), (34, 42), (43, 52), (52, 53), (54, 56), (56, 58), (59, 62), (63, 67), (68, 76), (76, 77), (77, 78), (79, 83), (84, 88), (89, 91), (92, 93), (94, 100), (101, 107), (108, 110), (111, 114), (115, 121), (122, 126), (126, 127), (128, 139), (140, 142), (143, 148), (149, 151), (152, 155), (156, 160), (161, 169), (170, 173), (174, 180), (181, 183), (183, 184), (185, 187), (188, 189), (190, 196), (197, 203), (204, 206), (207, 213), (214, 218), (219, 223), (224, 226), (226, 229), (229, 232), (233, 237), (238, 241), (242, 248), (249, 250), (250, 251), (251, 254), (254, 256), (257, 259), (260, 262), (263, 264), (264, 265), (265, 268), (268, 269), (269, 270), (271, 275), (276, 278), (279, 282), (283, 287), (288, 296), (297, 299), (300, 303), (304, 312), (313, 315), (316, 319), (320, 326), (327, 332), (332, 333), (334, 345), (346, 352), (353, 356), (357, 358), (358, 361), (361, 365), (366, 368), (369, 372), (373, 374), (0, 0)], [(0, 0), (0, 4), (5, 7), (8, 10), (11, 16), (17, 19), (20, 23), (24, 29), (30, 34), (35, 39), (40, 48), (48, 49), (0, 0), (174, 180), (181, 183), (183, 184), (185, 187), (188, 189), (190, 196), (197, 203), (204, 206), (207, 213), (214, 218), (219, 223), (224, 226), (226, 229), (229, 232), (233, 237), (238, 241), (242, 248), (249, 250), (250, 251), (251, 254), (254, 256), (257, 259), (260, 262), (263, 264), (264, 265), (265, 268), (268, 269), (269, 270), (271, 275), (276, 278), (279, 282), (283, 287), (288, 296), (297, 299), (300, 303), (304, 312), (313, 315), (316, 319), (320, 326), (327, 332), (332, 333), (334, 345), (346, 352), (353, 356), (357, 358), (358, 361), (361, 365), (366, 368), (369, 372), (373, 374), (374, 377), (377, 379), (379, 380), (381, 382), (383, 389), (390, 395), (396, 398), (399, 405), (406, 409), (410, 420), (420, 421), (422, 424), (425, 427), (428, 429), (430, 437), (438, 440), (441, 444), (445, 446), (446, 449), (449, 451), (452, 454), (455, 458), (458, 462), (462, 463), (464, 470), (471, 476), (477, 480), (481, 487), (488, 492), (493, 500), (500, 502), (503, 511), (512, 514), (515, 520), (521, 525), (525, 528), (0, 0)], [(0, 0), (0, 4), (5, 7), (8, 10), (11, 16), (17, 19), (20, 23), (24, 29), (30, 34), (35, 39), (40, 48), (48, 49), (0, 0), (313, 315), (316, 319), (320, 326), (327, 332), (332, 333), (334, 345), (346, 352), (353, 356), (357, 358), (358, 361), (361, 365), (366, 368), (369, 372), (373, 374), (374, 377), (377, 379), (379, 380), (381, 382), (383, 389), (390, 395), (396, 398), (399, 405), (406, 409), (410, 420), (420, 421), (422, 424), (425, 427), (428, 429), (430, 437), (438, 440), (441, 444), (445, 446), (446, 449), (449, 451), (452, 454), (455, 458), (458, 462), (462, 463), (464, 470), (471, 476), (477, 480), (481, 487), (488, 492), (493, 500), (500, 502), (503, 511), (512, 514), (515, 520), (521, 525), (525, 528), (528, 531), (532, 534), (534, 537), (537, 541), (542, 544), (545, 549), (549, 550), (551, 553), (554, 557), (558, 561), (562, 564), (565, 568), (569, 573), (574, 579), (580, 581), (581, 584), (585, 587), (588, 589), (590, 596), (597, 601), (602, 606), (607, 615), (616, 623), (624, 625), (626, 633), (634, 637), (638, 641), (642, 646), (647, 651), (651, 652), (652, 653), (654, 656), (657, 658), (659, 665), (665, 666), (667, 673), (0, 0)], [(0, 0), (0, 4), (5, 7), (8, 10), (11, 16), (17, 19), (20, 23), (24, 29), (30, 34), (35, 39), (40, 48), (48, 49), (0, 0), (458, 462), (462, 463), (464, 470), (471, 476), (477, 480), (481, 487), (488, 492), (493, 500), (500, 502), (503, 511), (512, 514), (515, 520), (521, 525), (525, 528), (528, 531), (532, 534), (534, 537), (537, 541), (542, 544), (545, 549), (549, 550), (551, 553), (554, 557), (558, 561), (562, 564), (565, 568), (569, 573), (574, 579), (580, 581), (581, 584), (585, 587), (588, 589), (590, 596), (597, 601), (602, 606), (607, 615), (616, 623), (624, 625), (626, 633), (634, 637), (638, 641), (642, 646), (647, 651), (651, 652), (652, 653), (654, 656), (657, 658), (659, 665), (665, 666), (667, 673), (674, 679), (680, 686), (687, 689), (690, 694), (694, 695), (0, 0)], [(0, 0), (0, 3), (4, 12), (13, 15), (16, 19), (20, 26), (27, 32), (33, 35), (36, 41), (42, 46), (47, 49), (50, 56), (57, 59), (60, 65), (66, 75), (75, 76), (0, 0), (0, 13), (13, 15), (15, 16), (17, 20), (21, 27), (28, 31), (32, 33), (34, 42), (43, 52), (52, 53), (54, 56), (56, 58), (59, 62), (63, 67), (68, 76), (76, 77), (77, 78), (79, 83), (84, 88), (89, 91), (92, 93), (94, 100), (101, 107), (108, 110), (111, 114), (115, 121), (122, 126), (126, 127), (128, 139), (140, 142), (143, 148), (149, 151), (152, 155), (156, 160), (161, 169), (170, 173), (174, 180), (181, 183), (183, 184), (185, 187), (188, 189), (190, 196), (197, 203), (204, 206), (207, 213), (214, 218), (219, 223), (224, 226), (226, 229), (229, 232), (233, 237), (238, 241), (242, 248), (249, 250), (250, 251), (251, 254), (254, 256), (257, 259), (260, 262), (263, 264), (264, 265), (265, 268), (268, 269), (269, 270), (271, 275), (276, 278), (279, 282), (283, 287), (288, 296), (297, 299), (300, 303), (304, 312), (313, 315), (316, 319), (320, 326), (327, 332), (332, 333), (334, 345), (346, 352), (353, 356), (357, 358), (358, 361), (0, 0)], [(0, 0), (0, 3), (4, 12), (13, 15), (16, 19), (20, 26), (27, 32), (33, 35), (36, 41), (42, 46), (47, 49), (50, 56), (57, 59), (60, 65), (66, 75), (75, 76), (0, 0), (152, 155), (156, 160), (161, 169), (170, 173), (174, 180), (181, 183), (183, 184), (185, 187), (188, 189), (190, 196), (197, 203), (204, 206), (207, 213), (214, 218), (219, 223), (224, 226), (226, 229), (229, 232), (233, 237), (238, 241), (242, 248), (249, 250), (250, 251), (251, 254), (254, 256), (257, 259), (260, 262), (263, 264), (264, 265), (265, 268), (268, 269), (269, 270), (271, 275), (276, 278), (279, 282), (283, 287), (288, 296), (297, 299), (300, 303), (304, 312), (313, 315), (316, 319), (320, 326), (327, 332), (332, 333), (334, 345), (346, 352), (353, 356), (357, 358), (358, 361), (361, 365), (366, 368), (369, 372), (373, 374), (374, 377), (377, 379), (379, 380), (381, 382), (383, 389), (390, 395), (396, 398), (399, 405), (406, 409), (410, 420), (420, 421), (422, 424), (425, 427), (428, 429), (430, 437), (438, 440), (441, 444), (445, 446), (446, 449), (449, 451), (452, 454), (455, 458), (458, 462), (462, 463), (464, 470), (471, 476), (477, 480), (481, 487), (0, 0)], [(0, 0), (0, 3), (4, 12), (13, 15), (16, 19), (20, 26), (27, 32), (33, 35), (36, 41), (42, 46), (47, 49), (50, 56), (57, 59), (60, 65), (66, 75), (75, 76), (0, 0), (271, 275), (276, 278), (279, 282), (283, 287), (288, 296), (297, 299), (300, 303), (304, 312), (313, 315), (316, 319), (320, 326), (327, 332), (332, 333), (334, 345), (346, 352), (353, 356), (357, 358), (358, 361), (361, 365), (366, 368), (369, 372), (373, 374), (374, 377), (377, 379), (379, 380), (381, 382), (383, 389), (390, 395), (396, 398), (399, 405), (406, 409), (410, 420), (420, 421), (422, 424), (425, 427), (428, 429), (430, 437), (438, 440), (441, 444), (445, 446), (446, 449), (449, 451), (452, 454), (455, 458), (458, 462), (462, 463), (464, 470), (471, 476), (477, 480), (481, 487), (488, 492), (493, 500), (500, 502), (503, 511), (512, 514), (515, 520), (521, 525), (525, 528), (528, 531), (532, 534), (534, 537), (537, 541), (542, 544), (545, 549), (549, 550), (551, 553), (554, 557), (558, 561), (562, 564), (565, 568), (569, 573), (574, 579), (580, 581), (581, 584), (585, 587), (588, 589), (590, 596), (597, 601), (602, 606), (607, 615), (616, 623), (624, 625), (0, 0)], [(0, 0), (0, 3), (4, 12), (13, 15), (16, 19), (20, 26), (27, 32), (33, 35), (36, 41), (42, 46), (47, 49), (50, 56), (57, 59), (60, 65), (66, 75), (75, 76), (0, 0), (420, 421), (422, 424), (425, 427), (428, 429), (430, 437), (438, 440), (441, 444), (445, 446), (446, 449), (449, 451), (452, 454), (455, 458), (458, 462), (462, 463), (464, 470), (471, 476), (477, 480), (481, 487), (488, 492), (493, 500), (500, 502), (503, 511), (512, 514), (515, 520), (521, 525), (525, 528), (528, 531), (532, 534), (534, 537), (537, 541), (542, 544), (545, 549), (549, 550), (551, 553), (554, 557), (558, 561), (562, 564), (565, 568), (569, 573), (574, 579), (580, 581), (581, 584), (585, 587), (588, 589), (590, 596), (597, 601), (602, 606), (607, 615), (616, 623), (624, 625), (626, 633), (634, 637), (638, 641), (642, 646), (647, 651), (651, 652), (652, 653), (654, 656), (657, 658), (659, 665), (665, 666), (667, 673), (674, 679), (680, 686), (687, 689), (690, 694), (694, 695), (0, 0)]], 'overflow_to_sample_mapping': [0, 0, 0, 0, 1, 1, 1, 1, 2, 2, 2, 2]}"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ],
      "source": [
        "inputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "b9a02ae1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b9a02ae1",
        "outputId": "451f713d-9bc4-4ff8-efdb-021ffeb7c136"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CLS] To whom did the Virgin Mary allegedly appear in 1858 in Lourdes France? [SEP] Architecturally, the school has a Catholic character. Atop the Main Building's gold dome is a golden statue of the Virgin Mary. Immediately in front of the Main Building and facing it, is a copper statue of Christ with arms upraised with the legend \" Venite Ad Me Omnes \". Next to the Main Building is the Basilica of the Sacred Heart. Immediately behind the basi [SEP]\n",
            "[CLS] To whom did the Virgin Mary allegedly appear in 1858 in Lourdes France? [SEP] the Main Building and facing it, is a copper statue of Christ with arms upraised with the legend \" Venite Ad Me Omnes \". Next to the Main Building is the Basilica of the Sacred Heart. Immediately behind the basilica is the Grotto, a Marian place of prayer and reflection. It is a replica of the grotto at Lourdes, France where the Virgin [SEP]\n",
            "[CLS] To whom did the Virgin Mary allegedly appear in 1858 in Lourdes France? [SEP] Next to the Main Building is the Basilica of the Sacred Heart. Immediately behind the basilica is the Grotto, a Marian place of prayer and reflection. It is a replica of the grotto at Lourdes, France where the Virgin Mary reputedly appeared to Saint Bernadette Soubirous in 1858. At the end of the main drive ( and in a direct line that connects through 3 [SEP]\n",
            "[CLS] To whom did the Virgin Mary allegedly appear in 1858 in Lourdes France? [SEP]. It is a replica of the grotto at Lourdes, France where the Virgin Mary reputedly appeared to Saint Bernadette Soubirous in 1858. At the end of the main drive ( and in a direct line that connects through 3 statues and the Gold Dome ), is a simple, modern stone statue of Mary. [SEP]\n",
            "[CLS] What is in front of the Notre Dame Main Building? [SEP] Architecturally, the school has a Catholic character. Atop the Main Building's gold dome is a golden statue of the Virgin Mary. Immediately in front of the Main Building and facing it, is a copper statue of Christ with arms upraised with the legend \" Venite Ad Me Omnes \". Next to the Main Building is the Basilica of the Sacred Heart. Immediately behind the basilica is the G [SEP]\n",
            "[CLS] What is in front of the Notre Dame Main Building? [SEP] facing it, is a copper statue of Christ with arms upraised with the legend \" Venite Ad Me Omnes \". Next to the Main Building is the Basilica of the Sacred Heart. Immediately behind the basilica is the Grotto, a Marian place of prayer and reflection. It is a replica of the grotto at Lourdes, France where the Virgin Mary reputedly appeared to Saint Bernade [SEP]\n",
            "[CLS] What is in front of the Notre Dame Main Building? [SEP] of the Sacred Heart. Immediately behind the basilica is the Grotto, a Marian place of prayer and reflection. It is a replica of the grotto at Lourdes, France where the Virgin Mary reputedly appeared to Saint Bernadette Soubirous in 1858. At the end of the main drive ( and in a direct line that connects through 3 statues and the Gold Dome ), is a simple, modern [SEP]\n",
            "[CLS] What is in front of the Notre Dame Main Building? [SEP]rdes, France where the Virgin Mary reputedly appeared to Saint Bernadette Soubirous in 1858. At the end of the main drive ( and in a direct line that connects through 3 statues and the Gold Dome ), is a simple, modern stone statue of Mary. [SEP]\n",
            "[CLS] The Basilica of the Sacred heart at Notre Dame is beside to which structure? [SEP] Architecturally, the school has a Catholic character. Atop the Main Building's gold dome is a golden statue of the Virgin Mary. Immediately in front of the Main Building and facing it, is a copper statue of Christ with arms upraised with the legend \" Venite Ad Me Omnes \". Next to the Main Building is the Basilica of the Sacred Heart. Immediately behind the basi [SEP]\n",
            "[CLS] The Basilica of the Sacred heart at Notre Dame is beside to which structure? [SEP] the Main Building and facing it, is a copper statue of Christ with arms upraised with the legend \" Venite Ad Me Omnes \". Next to the Main Building is the Basilica of the Sacred Heart. Immediately behind the basilica is the Grotto, a Marian place of prayer and reflection. It is a replica of the grotto at Lourdes, France where the Virgin [SEP]\n",
            "[CLS] The Basilica of the Sacred heart at Notre Dame is beside to which structure? [SEP] Next to the Main Building is the Basilica of the Sacred Heart. Immediately behind the basilica is the Grotto, a Marian place of prayer and reflection. It is a replica of the grotto at Lourdes, France where the Virgin Mary reputedly appeared to Saint Bernadette Soubirous in 1858. At the end of the main drive ( and in a direct line that connects through 3 [SEP]\n",
            "[CLS] The Basilica of the Sacred heart at Notre Dame is beside to which structure? [SEP]. It is a replica of the grotto at Lourdes, France where the Virgin Mary reputedly appeared to Saint Bernadette Soubirous in 1858. At the end of the main drive ( and in a direct line that connects through 3 statues and the Gold Dome ), is a simple, modern stone statue of Mary. [SEP]\n"
          ]
        }
      ],
      "source": [
        "for ids in inputs[\"input_ids\"]:\n",
        "    print(tokenizer.decode(ids))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "8778e4a2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 120
        },
        "id": "8778e4a2",
        "outputId": "62df6654-d287-4972-97cc-d03cf1e8123f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method BatchEncoding.keys of {'input_ids': [[101, 1327, 1110, 1107, 1524, 1104, 1103, 10360, 8022, 4304, 4334, 136, 102, 22182, 1193, 117, 1103, 1278, 1144, 170, 2336, 1959, 119, 1335, 4184, 1103, 4304, 4334, 112, 188, 2284, 10945, 1110, 170, 5404, 5921, 1104, 1103, 6567, 2090, 119, 13301, 1107, 1524, 1104, 1103, 4304, 4334, 1105, 4749, 1122, 117, 1110, 170, 7335, 5921, 1104, 4028, 1114, 1739, 1146, 14089, 5591, 1114, 1103, 7051, 107, 159, 21462, 1566, 24930, 2508, 152, 1306, 3965, 107, 119, 5893, 1106, 1103, 4304, 4334, 1110, 1103, 19349, 1104, 1103, 11373, 4641, 119, 13301, 1481, 1103, 171, 17506, 9538, 1110, 1103, 144, 102], [101, 1327, 1110, 1107, 1524, 1104, 1103, 10360, 8022, 4304, 4334, 136, 102, 4749, 1122, 117, 1110, 170, 7335, 5921, 1104, 4028, 1114, 1739, 1146, 14089, 5591, 1114, 1103, 7051, 107, 159, 21462, 1566, 24930, 2508, 152, 1306, 3965, 107, 119, 5893, 1106, 1103, 4304, 4334, 1110, 1103, 19349, 1104, 1103, 11373, 4641, 119, 13301, 1481, 1103, 171, 17506, 9538, 1110, 1103, 144, 10595, 2430, 117, 170, 14789, 1282, 1104, 8070, 1105, 9284, 119, 1135, 1110, 170, 16498, 1104, 1103, 176, 10595, 2430, 1120, 10111, 20500, 117, 1699, 1187, 1103, 6567, 2090, 25153, 1193, 1691, 1106, 2216, 17666, 6397, 102], [101, 1327, 1110, 1107, 1524, 1104, 1103, 10360, 8022, 4304, 4334, 136, 102, 1104, 1103, 11373, 4641, 119, 13301, 1481, 1103, 171, 17506, 9538, 1110, 1103, 144, 10595, 2430, 117, 170, 14789, 1282, 1104, 8070, 1105, 9284, 119, 1135, 1110, 170, 16498, 1104, 1103, 176, 10595, 2430, 1120, 10111, 20500, 117, 1699, 1187, 1103, 6567, 2090, 25153, 1193, 1691, 1106, 2216, 17666, 6397, 3786, 1573, 25422, 13149, 1107, 8109, 119, 1335, 1103, 1322, 1104, 1103, 1514, 2797, 113, 1105, 1107, 170, 2904, 1413, 1115, 8200, 1194, 124, 11739, 1105, 1103, 3487, 17917, 114, 117, 1110, 170, 3014, 117, 2030, 102], [101, 1327, 1110, 1107, 1524, 1104, 1103, 10360, 8022, 4304, 4334, 136, 102, 20500, 117, 1699, 1187, 1103, 6567, 2090, 25153, 1193, 1691, 1106, 2216, 17666, 6397, 3786, 1573, 25422, 13149, 1107, 8109, 119, 1335, 1103, 1322, 1104, 1103, 1514, 2797, 113, 1105, 1107, 170, 2904, 1413, 1115, 8200, 1194, 124, 11739, 1105, 1103, 3487, 17917, 114, 117, 1110, 170, 3014, 117, 2030, 2576, 5921, 1104, 2090, 119, 102]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], 'offset_mapping': [[(0, 0), (0, 4), (5, 7), (8, 10), (11, 16), (17, 19), (20, 23), (24, 29), (30, 34), (35, 39), (40, 48), (48, 49), (0, 0), (0, 13), (13, 15), (15, 16), (17, 20), (21, 27), (28, 31), (32, 33), (34, 42), (43, 52), (52, 53), (54, 56), (56, 58), (59, 62), (63, 67), (68, 76), (76, 77), (77, 78), (79, 83), (84, 88), (89, 91), (92, 93), (94, 100), (101, 107), (108, 110), (111, 114), (115, 121), (122, 126), (126, 127), (128, 139), (140, 142), (143, 148), (149, 151), (152, 155), (156, 160), (161, 169), (170, 173), (174, 180), (181, 183), (183, 184), (185, 187), (188, 189), (190, 196), (197, 203), (204, 206), (207, 213), (214, 218), (219, 223), (224, 226), (226, 229), (229, 232), (233, 237), (238, 241), (242, 248), (249, 250), (250, 251), (251, 254), (254, 256), (257, 259), (260, 262), (263, 264), (264, 265), (265, 268), (268, 269), (269, 270), (271, 275), (276, 278), (279, 282), (283, 287), (288, 296), (297, 299), (300, 303), (304, 312), (313, 315), (316, 319), (320, 326), (327, 332), (332, 333), (334, 345), (346, 352), (353, 356), (357, 358), (358, 361), (361, 365), (366, 368), (369, 372), (373, 374), (0, 0)], [(0, 0), (0, 4), (5, 7), (8, 10), (11, 16), (17, 19), (20, 23), (24, 29), (30, 34), (35, 39), (40, 48), (48, 49), (0, 0), (174, 180), (181, 183), (183, 184), (185, 187), (188, 189), (190, 196), (197, 203), (204, 206), (207, 213), (214, 218), (219, 223), (224, 226), (226, 229), (229, 232), (233, 237), (238, 241), (242, 248), (249, 250), (250, 251), (251, 254), (254, 256), (257, 259), (260, 262), (263, 264), (264, 265), (265, 268), (268, 269), (269, 270), (271, 275), (276, 278), (279, 282), (283, 287), (288, 296), (297, 299), (300, 303), (304, 312), (313, 315), (316, 319), (320, 326), (327, 332), (332, 333), (334, 345), (346, 352), (353, 356), (357, 358), (358, 361), (361, 365), (366, 368), (369, 372), (373, 374), (374, 377), (377, 379), (379, 380), (381, 382), (383, 389), (390, 395), (396, 398), (399, 405), (406, 409), (410, 420), (420, 421), (422, 424), (425, 427), (428, 429), (430, 437), (438, 440), (441, 444), (445, 446), (446, 449), (449, 451), (452, 454), (455, 458), (458, 462), (462, 463), (464, 470), (471, 476), (477, 480), (481, 487), (488, 492), (493, 500), (500, 502), (503, 511), (512, 514), (515, 520), (521, 525), (525, 528), (0, 0)], [(0, 0), (0, 4), (5, 7), (8, 10), (11, 16), (17, 19), (20, 23), (24, 29), (30, 34), (35, 39), (40, 48), (48, 49), (0, 0), (313, 315), (316, 319), (320, 326), (327, 332), (332, 333), (334, 345), (346, 352), (353, 356), (357, 358), (358, 361), (361, 365), (366, 368), (369, 372), (373, 374), (374, 377), (377, 379), (379, 380), (381, 382), (383, 389), (390, 395), (396, 398), (399, 405), (406, 409), (410, 420), (420, 421), (422, 424), (425, 427), (428, 429), (430, 437), (438, 440), (441, 444), (445, 446), (446, 449), (449, 451), (452, 454), (455, 458), (458, 462), (462, 463), (464, 470), (471, 476), (477, 480), (481, 487), (488, 492), (493, 500), (500, 502), (503, 511), (512, 514), (515, 520), (521, 525), (525, 528), (528, 531), (532, 534), (534, 537), (537, 541), (542, 544), (545, 549), (549, 550), (551, 553), (554, 557), (558, 561), (562, 564), (565, 568), (569, 573), (574, 579), (580, 581), (581, 584), (585, 587), (588, 589), (590, 596), (597, 601), (602, 606), (607, 615), (616, 623), (624, 625), (626, 633), (634, 637), (638, 641), (642, 646), (647, 651), (651, 652), (652, 653), (654, 656), (657, 658), (659, 665), (665, 666), (667, 673), (0, 0)], [(0, 0), (0, 4), (5, 7), (8, 10), (11, 16), (17, 19), (20, 23), (24, 29), (30, 34), (35, 39), (40, 48), (48, 49), (0, 0), (458, 462), (462, 463), (464, 470), (471, 476), (477, 480), (481, 487), (488, 492), (493, 500), (500, 502), (503, 511), (512, 514), (515, 520), (521, 525), (525, 528), (528, 531), (532, 534), (534, 537), (537, 541), (542, 544), (545, 549), (549, 550), (551, 553), (554, 557), (558, 561), (562, 564), (565, 568), (569, 573), (574, 579), (580, 581), (581, 584), (585, 587), (588, 589), (590, 596), (597, 601), (602, 606), (607, 615), (616, 623), (624, 625), (626, 633), (634, 637), (638, 641), (642, 646), (647, 651), (651, 652), (652, 653), (654, 656), (657, 658), (659, 665), (665, 666), (667, 673), (674, 679), (680, 686), (687, 689), (690, 694), (694, 695), (0, 0)]], 'overflow_to_sample_mapping': [0, 0, 0, 0]}>"
            ],
            "text/html": [
              "<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n",
              "      pre.function-repr-contents {\n",
              "        overflow-x: auto;\n",
              "        padding: 8px 12px;\n",
              "        max-height: 500px;\n",
              "      }\n",
              "\n",
              "      pre.function-repr-contents.function-repr-contents-collapsed {\n",
              "        cursor: pointer;\n",
              "        max-height: 100px;\n",
              "      }\n",
              "    </style>\n",
              "    <pre style=\"white-space: initial; background:\n",
              "         var(--colab-secondary-surface-color); padding: 8px 12px;\n",
              "         border-bottom: 1px solid var(--colab-border-color);\"><b>transformers.tokenization_utils_base.BatchEncoding.keys</b><br/>def keys()</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py</a>D.keys() -&gt; a set-like object providing a view on D&#x27;s keys</pre>\n",
              "      <script>\n",
              "      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n",
              "        for (const element of document.querySelectorAll('.filepath')) {\n",
              "          element.style.display = 'block'\n",
              "          element.onclick = (event) => {\n",
              "            event.preventDefault();\n",
              "            event.stopPropagation();\n",
              "            google.colab.files.view(element.textContent, 281);\n",
              "          };\n",
              "        }\n",
              "      }\n",
              "      for (const element of document.querySelectorAll('.function-repr-contents')) {\n",
              "        element.onclick = (event) => {\n",
              "          event.preventDefault();\n",
              "          event.stopPropagation();\n",
              "          element.classList.toggle('function-repr-contents-collapsed');\n",
              "        };\n",
              "      }\n",
              "      </script>\n",
              "      </div>"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ],
      "source": [
        "# recreate inputs for just a single context-question pair\n",
        "inputs = tokenizer(\n",
        "    question,\n",
        "    context,\n",
        "    max_length=100,\n",
        "    truncation = \"only_second\",\n",
        "    stride=50,\n",
        "    return_overflowing_tokens=True,\n",
        "    return_offsets_mapping=True,\n",
        ")\n",
        "inputs.keys"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "id": "b12d844f",
      "metadata": {
        "scrolled": false,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b12d844f",
        "outputId": "f142b47e-af4f-4819-98a3-0672e2ef91ca"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[(0, 0),\n",
              "  (0, 4),\n",
              "  (5, 7),\n",
              "  (8, 10),\n",
              "  (11, 16),\n",
              "  (17, 19),\n",
              "  (20, 23),\n",
              "  (24, 29),\n",
              "  (30, 34),\n",
              "  (35, 39),\n",
              "  (40, 48),\n",
              "  (48, 49),\n",
              "  (0, 0),\n",
              "  (0, 13),\n",
              "  (13, 15),\n",
              "  (15, 16),\n",
              "  (17, 20),\n",
              "  (21, 27),\n",
              "  (28, 31),\n",
              "  (32, 33),\n",
              "  (34, 42),\n",
              "  (43, 52),\n",
              "  (52, 53),\n",
              "  (54, 56),\n",
              "  (56, 58),\n",
              "  (59, 62),\n",
              "  (63, 67),\n",
              "  (68, 76),\n",
              "  (76, 77),\n",
              "  (77, 78),\n",
              "  (79, 83),\n",
              "  (84, 88),\n",
              "  (89, 91),\n",
              "  (92, 93),\n",
              "  (94, 100),\n",
              "  (101, 107),\n",
              "  (108, 110),\n",
              "  (111, 114),\n",
              "  (115, 121),\n",
              "  (122, 126),\n",
              "  (126, 127),\n",
              "  (128, 139),\n",
              "  (140, 142),\n",
              "  (143, 148),\n",
              "  (149, 151),\n",
              "  (152, 155),\n",
              "  (156, 160),\n",
              "  (161, 169),\n",
              "  (170, 173),\n",
              "  (174, 180),\n",
              "  (181, 183),\n",
              "  (183, 184),\n",
              "  (185, 187),\n",
              "  (188, 189),\n",
              "  (190, 196),\n",
              "  (197, 203),\n",
              "  (204, 206),\n",
              "  (207, 213),\n",
              "  (214, 218),\n",
              "  (219, 223),\n",
              "  (224, 226),\n",
              "  (226, 229),\n",
              "  (229, 232),\n",
              "  (233, 237),\n",
              "  (238, 241),\n",
              "  (242, 248),\n",
              "  (249, 250),\n",
              "  (250, 251),\n",
              "  (251, 254),\n",
              "  (254, 256),\n",
              "  (257, 259),\n",
              "  (260, 262),\n",
              "  (263, 264),\n",
              "  (264, 265),\n",
              "  (265, 268),\n",
              "  (268, 269),\n",
              "  (269, 270),\n",
              "  (271, 275),\n",
              "  (276, 278),\n",
              "  (279, 282),\n",
              "  (283, 287),\n",
              "  (288, 296),\n",
              "  (297, 299),\n",
              "  (300, 303),\n",
              "  (304, 312),\n",
              "  (313, 315),\n",
              "  (316, 319),\n",
              "  (320, 326),\n",
              "  (327, 332),\n",
              "  (332, 333),\n",
              "  (334, 345),\n",
              "  (346, 352),\n",
              "  (353, 356),\n",
              "  (357, 358),\n",
              "  (358, 361),\n",
              "  (361, 365),\n",
              "  (366, 368),\n",
              "  (369, 372),\n",
              "  (373, 374),\n",
              "  (0, 0)],\n",
              " [(0, 0),\n",
              "  (0, 4),\n",
              "  (5, 7),\n",
              "  (8, 10),\n",
              "  (11, 16),\n",
              "  (17, 19),\n",
              "  (20, 23),\n",
              "  (24, 29),\n",
              "  (30, 34),\n",
              "  (35, 39),\n",
              "  (40, 48),\n",
              "  (48, 49),\n",
              "  (0, 0),\n",
              "  (174, 180),\n",
              "  (181, 183),\n",
              "  (183, 184),\n",
              "  (185, 187),\n",
              "  (188, 189),\n",
              "  (190, 196),\n",
              "  (197, 203),\n",
              "  (204, 206),\n",
              "  (207, 213),\n",
              "  (214, 218),\n",
              "  (219, 223),\n",
              "  (224, 226),\n",
              "  (226, 229),\n",
              "  (229, 232),\n",
              "  (233, 237),\n",
              "  (238, 241),\n",
              "  (242, 248),\n",
              "  (249, 250),\n",
              "  (250, 251),\n",
              "  (251, 254),\n",
              "  (254, 256),\n",
              "  (257, 259),\n",
              "  (260, 262),\n",
              "  (263, 264),\n",
              "  (264, 265),\n",
              "  (265, 268),\n",
              "  (268, 269),\n",
              "  (269, 270),\n",
              "  (271, 275),\n",
              "  (276, 278),\n",
              "  (279, 282),\n",
              "  (283, 287),\n",
              "  (288, 296),\n",
              "  (297, 299),\n",
              "  (300, 303),\n",
              "  (304, 312),\n",
              "  (313, 315),\n",
              "  (316, 319),\n",
              "  (320, 326),\n",
              "  (327, 332),\n",
              "  (332, 333),\n",
              "  (334, 345),\n",
              "  (346, 352),\n",
              "  (353, 356),\n",
              "  (357, 358),\n",
              "  (358, 361),\n",
              "  (361, 365),\n",
              "  (366, 368),\n",
              "  (369, 372),\n",
              "  (373, 374),\n",
              "  (374, 377),\n",
              "  (377, 379),\n",
              "  (379, 380),\n",
              "  (381, 382),\n",
              "  (383, 389),\n",
              "  (390, 395),\n",
              "  (396, 398),\n",
              "  (399, 405),\n",
              "  (406, 409),\n",
              "  (410, 420),\n",
              "  (420, 421),\n",
              "  (422, 424),\n",
              "  (425, 427),\n",
              "  (428, 429),\n",
              "  (430, 437),\n",
              "  (438, 440),\n",
              "  (441, 444),\n",
              "  (445, 446),\n",
              "  (446, 449),\n",
              "  (449, 451),\n",
              "  (452, 454),\n",
              "  (455, 458),\n",
              "  (458, 462),\n",
              "  (462, 463),\n",
              "  (464, 470),\n",
              "  (471, 476),\n",
              "  (477, 480),\n",
              "  (481, 487),\n",
              "  (488, 492),\n",
              "  (493, 500),\n",
              "  (500, 502),\n",
              "  (503, 511),\n",
              "  (512, 514),\n",
              "  (515, 520),\n",
              "  (521, 525),\n",
              "  (525, 528),\n",
              "  (0, 0)],\n",
              " [(0, 0),\n",
              "  (0, 4),\n",
              "  (5, 7),\n",
              "  (8, 10),\n",
              "  (11, 16),\n",
              "  (17, 19),\n",
              "  (20, 23),\n",
              "  (24, 29),\n",
              "  (30, 34),\n",
              "  (35, 39),\n",
              "  (40, 48),\n",
              "  (48, 49),\n",
              "  (0, 0),\n",
              "  (313, 315),\n",
              "  (316, 319),\n",
              "  (320, 326),\n",
              "  (327, 332),\n",
              "  (332, 333),\n",
              "  (334, 345),\n",
              "  (346, 352),\n",
              "  (353, 356),\n",
              "  (357, 358),\n",
              "  (358, 361),\n",
              "  (361, 365),\n",
              "  (366, 368),\n",
              "  (369, 372),\n",
              "  (373, 374),\n",
              "  (374, 377),\n",
              "  (377, 379),\n",
              "  (379, 380),\n",
              "  (381, 382),\n",
              "  (383, 389),\n",
              "  (390, 395),\n",
              "  (396, 398),\n",
              "  (399, 405),\n",
              "  (406, 409),\n",
              "  (410, 420),\n",
              "  (420, 421),\n",
              "  (422, 424),\n",
              "  (425, 427),\n",
              "  (428, 429),\n",
              "  (430, 437),\n",
              "  (438, 440),\n",
              "  (441, 444),\n",
              "  (445, 446),\n",
              "  (446, 449),\n",
              "  (449, 451),\n",
              "  (452, 454),\n",
              "  (455, 458),\n",
              "  (458, 462),\n",
              "  (462, 463),\n",
              "  (464, 470),\n",
              "  (471, 476),\n",
              "  (477, 480),\n",
              "  (481, 487),\n",
              "  (488, 492),\n",
              "  (493, 500),\n",
              "  (500, 502),\n",
              "  (503, 511),\n",
              "  (512, 514),\n",
              "  (515, 520),\n",
              "  (521, 525),\n",
              "  (525, 528),\n",
              "  (528, 531),\n",
              "  (532, 534),\n",
              "  (534, 537),\n",
              "  (537, 541),\n",
              "  (542, 544),\n",
              "  (545, 549),\n",
              "  (549, 550),\n",
              "  (551, 553),\n",
              "  (554, 557),\n",
              "  (558, 561),\n",
              "  (562, 564),\n",
              "  (565, 568),\n",
              "  (569, 573),\n",
              "  (574, 579),\n",
              "  (580, 581),\n",
              "  (581, 584),\n",
              "  (585, 587),\n",
              "  (588, 589),\n",
              "  (590, 596),\n",
              "  (597, 601),\n",
              "  (602, 606),\n",
              "  (607, 615),\n",
              "  (616, 623),\n",
              "  (624, 625),\n",
              "  (626, 633),\n",
              "  (634, 637),\n",
              "  (638, 641),\n",
              "  (642, 646),\n",
              "  (647, 651),\n",
              "  (651, 652),\n",
              "  (652, 653),\n",
              "  (654, 656),\n",
              "  (657, 658),\n",
              "  (659, 665),\n",
              "  (665, 666),\n",
              "  (667, 673),\n",
              "  (0, 0)],\n",
              " [(0, 0),\n",
              "  (0, 4),\n",
              "  (5, 7),\n",
              "  (8, 10),\n",
              "  (11, 16),\n",
              "  (17, 19),\n",
              "  (20, 23),\n",
              "  (24, 29),\n",
              "  (30, 34),\n",
              "  (35, 39),\n",
              "  (40, 48),\n",
              "  (48, 49),\n",
              "  (0, 0),\n",
              "  (458, 462),\n",
              "  (462, 463),\n",
              "  (464, 470),\n",
              "  (471, 476),\n",
              "  (477, 480),\n",
              "  (481, 487),\n",
              "  (488, 492),\n",
              "  (493, 500),\n",
              "  (500, 502),\n",
              "  (503, 511),\n",
              "  (512, 514),\n",
              "  (515, 520),\n",
              "  (521, 525),\n",
              "  (525, 528),\n",
              "  (528, 531),\n",
              "  (532, 534),\n",
              "  (534, 537),\n",
              "  (537, 541),\n",
              "  (542, 544),\n",
              "  (545, 549),\n",
              "  (549, 550),\n",
              "  (551, 553),\n",
              "  (554, 557),\n",
              "  (558, 561),\n",
              "  (562, 564),\n",
              "  (565, 568),\n",
              "  (569, 573),\n",
              "  (574, 579),\n",
              "  (580, 581),\n",
              "  (581, 584),\n",
              "  (585, 587),\n",
              "  (588, 589),\n",
              "  (590, 596),\n",
              "  (597, 601),\n",
              "  (602, 606),\n",
              "  (607, 615),\n",
              "  (616, 623),\n",
              "  (624, 625),\n",
              "  (626, 633),\n",
              "  (634, 637),\n",
              "  (638, 641),\n",
              "  (642, 646),\n",
              "  (647, 651),\n",
              "  (651, 652),\n",
              "  (652, 653),\n",
              "  (654, 656),\n",
              "  (657, 658),\n",
              "  (659, 665),\n",
              "  (665, 666),\n",
              "  (667, 673),\n",
              "  (674, 679),\n",
              "  (680, 686),\n",
              "  (687, 689),\n",
              "  (690, 694),\n",
              "  (694, 695),\n",
              "  (0, 0)]]"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ],
      "source": [
        "#offset mapping\n",
        "#it tells us the location of each token\n",
        "#notes:\n",
        "#special tokens take up 0 space - (0, 0)\n",
        "#the question portion is the same for each sample\n",
        "#the context portion starting point increases in each sample\n",
        "#last token is 1 char, (694,695), as it is the question mark\n",
        "inputs['offset_mapping']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "id": "24bb2795",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "24bb2795",
        "outputId": "87719d66-5ced-4fcc-ba00-dd8a52241c46"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ],
      "source": [
        "len(inputs['offset_mapping'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "id": "8d2d5930",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8d2d5930",
        "outputId": "134efe1f-7534-45fd-e4b9-8c003edd5146"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "100"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ],
      "source": [
        "len(inputs['offset_mapping'][0])\n",
        "#the output is 100 as we specified truncation at 100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "id": "94bd5fa2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "94bd5fa2",
        "outputId": "8adb3c9d-a9c9-4617-f181-94acf0d3f940"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[None, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, None, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, None]\n"
          ]
        }
      ],
      "source": [
        "print(inputs.sequence_ids(0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "id": "23e389c0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "23e389c0",
        "outputId": "df4775cf-5d23-49a5-b189-d523bbb62db6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'text': ['a copper statue of Christ'], 'answer_start': [188]}"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ],
      "source": [
        "# problem: the position of the answer will change in each\n",
        "# window of the context\n",
        "# the answer is also the target for the neural network\n",
        "# how can we recompute the targets for each context window?\n",
        "\n",
        "# since we took the question and context from this sample earlier\n",
        "answer = raw_datasets[\"train\"][1][\"answers\"]\n",
        "answer"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(inputs.sequence_ids(0))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7G-WKtmWkWc-",
        "outputId": "e9695bd8-5689-4296-a29d-22194f452e4a"
      },
      "id": "7G-WKtmWkWc-",
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "list"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# find the start and end of the context (the first and last '1')\n",
        "sequence_ids = inputs.sequence_ids(0)\n",
        "\n",
        "ctx_start = sequence_ids.index(1) # first occurrence\n",
        "ctx_end = len(sequence_ids) - sequence_ids[::-1].index(1) - 1 # last occurrence\n",
        "\n",
        "ctx_start, ctx_end"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oyp4acrYkWyp",
        "outputId": "b0e80165-f106-49cc-ec49-d8402304c5f3"
      },
      "id": "oyp4acrYkWyp",
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(13, 98)"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# check whether or not the answer is fully contained within the context\n",
        "# if not, target is (start, end) = (0, 0)\n",
        "\n",
        "ans_start_char = answer['answer_start'][0]\n",
        "ans_end_char = ans_start_char + len(answer['text'][0])\n",
        "\n",
        "offset = inputs['offset_mapping'][0]\n",
        "\n",
        "start_idx = 0\n",
        "end_idx = 0\n",
        "\n",
        "if offset[ctx_start][0] > ans_start_char or offset[ctx_end][1] < ans_end_char:\n",
        "  print(\"target is (0, 0)\")\n",
        "  # nothing else to do\n",
        "else:\n",
        "  # find the start and end TOKEN positions\n",
        "\n",
        "  # the 'trick' is knowing what is in units of tokens and what is in\n",
        "  # units of characters\n",
        "\n",
        "  # recall: the offset_mapping contains the character positions of each token\n",
        "\n",
        "  i = ctx_start\n",
        "  for start_end_char in offset[ctx_start:]:\n",
        "    start, end = start_end_char\n",
        "    if start == ans_start_char:\n",
        "      start_idx = i\n",
        "      # don't break yet\n",
        "\n",
        "    if end == ans_end_char:\n",
        "      end_idx = i\n",
        "      break\n",
        "\n",
        "    i += 1\n",
        "\n",
        "start_idx, end_idx"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3CyExvkjkXIr",
        "outputId": "7102a380-da6c-49d5-e614-25396b66a10b"
      },
      "id": "3CyExvkjkXIr",
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(53, 57)"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# check\n",
        "input_ids = inputs['input_ids'][0]\n",
        "input_ids[start_idx : end_idx + 1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "in-pKhfpkXeo",
        "outputId": "6cd49015-1d1b-4e2f-87a1-e21b7768d243"
      },
      "id": "in-pKhfpkXeo",
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[170, 7335, 5921, 1104, 4028]"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.decode(input_ids[start_idx : end_idx + 1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "QZlwCL9zkX1B",
        "outputId": "351293eb-8f0b-45e8-b57f-acd03ee8c2d6"
      },
      "id": "QZlwCL9zkX1B",
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'a copper statue of Christ'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def find_answer_token_idx(\n",
        "    ctx_start,\n",
        "    ctx_end,\n",
        "    ans_start_char,\n",
        "    ans_end_char,\n",
        "    offset):\n",
        "\n",
        "  start_idx = 0\n",
        "  end_idx = 0\n",
        "\n",
        "  if offset[ctx_start][0] > ans_start_char or offset[ctx_end][1] < ans_end_char:\n",
        "    pass\n",
        "    # print(\"target is (0, 0)\")\n",
        "    # nothing else to do\n",
        "  else:\n",
        "    # find the start and end TOKEN positions\n",
        "\n",
        "    # the 'trick' is knowing what is in units of tokens and what is in\n",
        "    # units of characters\n",
        "\n",
        "    # recall: the offset_mapping contains the character positions of each token\n",
        "\n",
        "    i = ctx_start\n",
        "    for start_end_char in offset[ctx_start:]:\n",
        "      start, end = start_end_char\n",
        "      if start == ans_start_char:\n",
        "        start_idx = i\n",
        "        # don't break yet\n",
        "\n",
        "      if end == ans_end_char:\n",
        "        end_idx = i\n",
        "        break\n",
        "\n",
        "      i += 1\n",
        "  return start_idx, end_idx"
      ],
      "metadata": {
        "id": "d-CQoZ-ckYLm"
      },
      "id": "d-CQoZ-ckYLm",
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# try it on all context windows\n",
        "# sometimes, the answer won't appear!\n",
        "\n",
        "start_idxs = []\n",
        "end_idxs = []\n",
        "\n",
        "for i, offset in enumerate(inputs['offset_mapping']):\n",
        "  # the final window may not be full size - can't assume 100\n",
        "  sequence_ids = inputs.sequence_ids(i)\n",
        "\n",
        "  # find start + end of context (first 1 and last 1)\n",
        "  ctx_start = sequence_ids.index(1)\n",
        "  ctx_end = len(sequence_ids) - sequence_ids[::-1].index(1) - 1\n",
        "\n",
        "  start_idx, end_idx = find_answer_token_idx(\n",
        "    ctx_start,\n",
        "    ctx_end,\n",
        "    ans_start_char,\n",
        "    ans_end_char,\n",
        "    offset)\n",
        "\n",
        "  start_idxs.append(start_idx)\n",
        "  end_idxs.append(end_idx)\n",
        "\n",
        "start_idxs, end_idxs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zFGhSVHZkYg0",
        "outputId": "34b4fde4-dfca-4145-a46a-1bfd4da0089c"
      },
      "id": "zFGhSVHZkYg0",
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([53, 17, 0, 0], [57, 21, 0, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# some questions have leading and/or trailing whitespace\n",
        "for q in raw_datasets[\"train\"][\"question\"][:1000]:\n",
        "  if q.strip() != q:\n",
        "    print(q)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yqjy3lpEkY07",
        "outputId": "5497ddee-2a7d-425e-e51c-fb0fa89f3825"
      },
      "id": "Yqjy3lpEkY07",
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "In what city and state did Beyonce  grow up? \n",
            " The album, Dangerously in Love  achieved what spot on the Billboard Top 100 chart?\n",
            "Which song did Beyonce sing at the first couple's inaugural ball? \n",
            "What event did Beyoncé perform at one month after Obama's inauguration? \n",
            "Where was the album released? \n",
            "What movie influenced Beyonce towards empowerment themes? \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# now we are ready to process (tokenize) the training data\n",
        "# (i.e. expand question+context pairs into question+smaller context windows)\n",
        "\n",
        "# Google used 384 for SQuAD\n",
        "max_length = 384\n",
        "stride = 128\n",
        "\n",
        "def tokenize_fn_train(batch):\n",
        "  # some questions have leading and/or trailing whitespace\n",
        "  questions = [q.strip() for q in batch[\"question\"]]\n",
        "\n",
        "  # tokenize the data (with padding this time)\n",
        "  # since most contexts are long, we won't bother to pad per-minibatch\n",
        "  inputs = tokenizer(\n",
        "    questions,\n",
        "    batch[\"context\"],\n",
        "    max_length=max_length,\n",
        "    truncation=\"only_second\",\n",
        "    stride=stride,\n",
        "    return_overflowing_tokens=True,\n",
        "    return_offsets_mapping=True,\n",
        "    padding=\"max_length\",\n",
        "  )\n",
        "\n",
        "  # we don't need these later so remove them\n",
        "  offset_mapping = inputs.pop(\"offset_mapping\")\n",
        "  orig_sample_idxs = inputs.pop(\"overflow_to_sample_mapping\")\n",
        "  answers = batch['answers']\n",
        "  start_idxs, end_idxs = [], []\n",
        "\n",
        "  # same loop as above\n",
        "  for i, offset in enumerate(offset_mapping):\n",
        "    sample_idx = orig_sample_idxs[i]\n",
        "    answer = answers[sample_idx]\n",
        "\n",
        "    ans_start_char = answer['answer_start'][0]\n",
        "    ans_end_char = ans_start_char + len(answer['text'][0])\n",
        "\n",
        "    sequence_ids = inputs.sequence_ids(i)\n",
        "\n",
        "    # find start + end of context (first 1 and last 1)\n",
        "    ctx_start = sequence_ids.index(1)\n",
        "    ctx_end = len(sequence_ids) - sequence_ids[::-1].index(1) - 1\n",
        "\n",
        "    start_idx, end_idx = find_answer_token_idx(\n",
        "      ctx_start,\n",
        "      ctx_end,\n",
        "      ans_start_char,\n",
        "      ans_end_char,\n",
        "      offset)\n",
        "\n",
        "    start_idxs.append(start_idx)\n",
        "    end_idxs.append(end_idx)\n",
        "\n",
        "  inputs[\"start_positions\"] = start_idxs\n",
        "  inputs[\"end_positions\"] = end_idxs\n",
        "  return inputs"
      ],
      "metadata": {
        "id": "zyVGlTUmkZXD"
      },
      "id": "zyVGlTUmkZXD",
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = raw_datasets[\"train\"].map(\n",
        "  tokenize_fn_train,\n",
        "  batched=True,\n",
        "  remove_columns=raw_datasets[\"train\"].column_names,\n",
        ")\n",
        "len(raw_datasets[\"train\"]), len(train_dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h3jZKk_FkZyN",
        "outputId": "12336f05-fdde-4508-d1a4-e8f28ad50626"
      },
      "id": "h3jZKk_FkZyN",
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(87599, 88729)"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# note: we'll keep these IDs for later\n",
        "raw_datasets[\"validation\"][0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CQzN6l-VkaNj",
        "outputId": "b9a58990-110d-48b0-d439-46c1b2f6af01"
      },
      "id": "CQzN6l-VkaNj",
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'id': '56be4db0acb8001400a502ec',\n",
              " 'title': 'Super_Bowl_50',\n",
              " 'context': 'Super Bowl 50 was an American football game to determine the champion of the National Football League (NFL) for the 2015 season. The American Football Conference (AFC) champion Denver Broncos defeated the National Football Conference (NFC) champion Carolina Panthers 24–10 to earn their third Super Bowl title. The game was played on February 7, 2016, at Levi\\'s Stadium in the San Francisco Bay Area at Santa Clara, California. As this was the 50th Super Bowl, the league emphasized the \"golden anniversary\" with various gold-themed initiatives, as well as temporarily suspending the tradition of naming each Super Bowl game with Roman numerals (under which the game would have been known as \"Super Bowl L\"), so that the logo could prominently feature the Arabic numerals 50.',\n",
              " 'question': 'Which NFL team represented the AFC at Super Bowl 50?',\n",
              " 'answers': {'text': ['Denver Broncos', 'Denver Broncos', 'Denver Broncos'],\n",
              "  'answer_start': [177, 177, 177]}}"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# tokenize the validation set differently\n",
        "# we won't need the targets since we will just compare with the original answer\n",
        "# also: overwrite offset_mapping with Nones in place of question\n",
        "def tokenize_fn_validation(batch):\n",
        "  # some questions have leading and/or trailing whitespace\n",
        "  questions = [q.strip() for q in batch[\"question\"]]\n",
        "\n",
        "  # tokenize the data (with padding this time)\n",
        "  # since most contexts are long, we won't bother to pad per-minibatch\n",
        "  inputs = tokenizer(\n",
        "    questions,\n",
        "    batch[\"context\"],\n",
        "    max_length=max_length,\n",
        "    truncation=\"only_second\",\n",
        "    stride=stride,\n",
        "    return_overflowing_tokens=True,\n",
        "    return_offsets_mapping=True,\n",
        "    padding=\"max_length\",\n",
        "  )\n",
        "\n",
        "  # we don't need these later so remove them\n",
        "  orig_sample_idxs = inputs.pop(\"overflow_to_sample_mapping\")\n",
        "  sample_ids = []\n",
        "\n",
        "  # rewrite offset mapping by replacing question tuples with None\n",
        "  # this will be helpful later on when we compute metrics\n",
        "  for i in range(len(inputs[\"input_ids\"])):\n",
        "    sample_idx = orig_sample_idxs[i]\n",
        "    sample_ids.append(batch['id'][sample_idx])\n",
        "\n",
        "    sequence_ids = inputs.sequence_ids(i)\n",
        "    offset = inputs[\"offset_mapping\"][i]\n",
        "    inputs[\"offset_mapping\"][i] = [\n",
        "      x if sequence_ids[j] == 1 else None for j, x in enumerate(offset)]\n",
        "\n",
        "  inputs['sample_id'] = sample_ids\n",
        "  return inputs"
      ],
      "metadata": {
        "id": "XvVaObX5lguo"
      },
      "id": "XvVaObX5lguo",
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "validation_dataset = raw_datasets[\"validation\"].map(\n",
        "  tokenize_fn_validation,\n",
        "  batched=True,\n",
        "    remove_columns=raw_datasets[\"validation\"].column_names,\n",
        ")\n",
        "len(raw_datasets[\"validation\"]), len(validation_dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "3796f3e2592b4a5c97da89079cfc82a1",
            "57ced85810cd4678b912b29a6c276a38",
            "a9e9f71a3fda4439b8dd00f72be86447",
            "d2eaf78f39714cfeb612ddc32a66a094",
            "a3ca06abf19248d582890c892fca831c",
            "0d0dc742d89c4665a7dc0ca3c47620a3",
            "b8522d46e7954fd2bac1a0bad9e81996",
            "384e57c913ed4376adb98a42ab947fd1",
            "60f0b2575f834e279baddc07f9df474f",
            "b5d22b017271412991f5037ac6b0a019",
            "2aaab1720fce418db61544869a19eca1"
          ]
        },
        "id": "tNYAND20lhDC",
        "outputId": "9213fa31-6c38-4127-c871-127072e2ef6c"
      },
      "id": "tNYAND20lhDC",
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/10570 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3796f3e2592b4a5c97da89079cfc82a1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10570, 10822)"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_metric\n",
        "\n",
        "metric = load_metric(\"squad\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZfXmZiYklhYJ",
        "outputId": "2c2310c0-8b3a-41c9-b716-8d2b31db03e2"
      },
      "id": "ZfXmZiYklhYJ",
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-54-0eb82bc40e87>:3: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library 🤗 Evaluate: https://huggingface.co/docs/evaluate\n",
            "  metric = load_metric(\"squad\")\n",
            "/usr/local/lib/python3.10/dist-packages/datasets/load.py:759: FutureWarning: The repository for squad contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.19.0/metrics/squad/squad.py\n",
            "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
            "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predicted_answers = [\n",
        "  {'id': '1', 'prediction_text': 'Albert Einstein'},\n",
        "  {'id': '2', 'prediction_text': 'physicist'},\n",
        "  {'id': '3', 'prediction_text': 'general relativity'},\n",
        "]\n",
        "true_answers = [\n",
        "  {'id': '1', 'answers': {'text': ['Albert Einstein'], 'answer_start': [100]}},\n",
        "  {'id': '2', 'answers': {'text': ['physicist'], 'answer_start': [100]}},\n",
        "  {'id': '3', 'answers': {'text': ['special relativity'], 'answer_start': [100]}},\n",
        "]\n",
        "\n",
        "# id and answer_start seem superfluous but you'll get an error if not included\n",
        "# exercise: remove them (one at a time) and see!\n",
        "metric.compute(predictions=predicted_answers, references=true_answers)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cr2p3dtwlhrb",
        "outputId": "7c835ba5-a438-4daa-f3fa-a94ba9df084c"
      },
      "id": "Cr2p3dtwlhrb",
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'exact_match': 66.66666666666667, 'f1': 83.33333333333333}"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# next problem: how to go from logits to prediction text?\n",
        "# to make it easier, let's work on an already-trained question-answering model\n",
        "small_validation_dataset = raw_datasets[\"validation\"].select(range(100))\n",
        "trained_checkpoint = \"distilbert-base-cased-distilled-squad\"\n",
        "\n",
        "tokenizer2 = AutoTokenizer.from_pretrained(trained_checkpoint)\n",
        "\n",
        "# temporarily assign tokenizer2 to tokenizer since it's used as a global\n",
        "# in tokenize_fn_validation\n",
        "old_tokenizer = tokenizer\n",
        "tokenizer = tokenizer2\n",
        "\n",
        "small_validation_processed = small_validation_dataset.map(\n",
        "    tokenize_fn_validation,\n",
        "    batched=True,\n",
        "    remove_columns=raw_datasets[\"validation\"].column_names,\n",
        ")\n",
        "\n",
        "# change it back\n",
        "tokenizer = old_tokenizer"
      ],
      "metadata": {
        "id": "dLmlC7WVlh_f"
      },
      "id": "dLmlC7WVlh_f",
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get the model outputs\n",
        "import torch\n",
        "from transformers import AutoModelForQuestionAnswering\n",
        "\n",
        "# the trained model doesn't use these columns\n",
        "small_model_inputs = small_validation_processed.remove_columns(\n",
        "  [\"sample_id\", \"offset_mapping\"])\n",
        "small_model_inputs.set_format(\"torch\")\n",
        "\n",
        "# get gpu device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# move tensors to gpu device\n",
        "small_model_inputs_gpu = {\n",
        "  k: small_model_inputs[k].to(device) for k in small_model_inputs.column_names\n",
        "}\n",
        "\n",
        "# download the model\n",
        "trained_model = AutoModelForQuestionAnswering.from_pretrained(\n",
        "  trained_checkpoint).to(device)\n",
        "\n",
        "# get the model outputs\n",
        "with torch.no_grad():\n",
        "  outputs = trained_model(**small_model_inputs_gpu)"
      ],
      "metadata": {
        "id": "bdByIdOXmAxg"
      },
      "id": "bdByIdOXmAxg",
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "outputs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N_4UN03ImBFQ",
        "outputId": "82b51ba9-7e2f-402d-a959-c07ca9c8d72c"
      },
      "id": "N_4UN03ImBFQ",
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "QuestionAnsweringModelOutput(loss=None, start_logits=tensor([[ -2.2607,  -5.1783,  -5.2709,  ...,  -9.5243,  -9.5183,  -9.5288],\n",
              "        [ -2.5961,  -5.5482,  -5.5313,  ...,  -9.9598,  -9.9533,  -9.9860],\n",
              "        [ -3.7127,  -7.1848,  -8.5388,  ..., -11.6557, -11.6571, -11.6505],\n",
              "        ...,\n",
              "        [ -2.0260,  -4.4167,  -4.4980,  ...,  -8.1479,  -8.1530,  -8.1760],\n",
              "        [ -4.1553,  -5.8304,  -7.1643,  ..., -10.5255, -10.5251, -10.4890],\n",
              "        [ -3.2000,  -5.8162,  -6.7249,  ...,  -9.4935,  -9.5038,  -9.4871]],\n",
              "       device='cuda:0'), end_logits=tensor([[ -0.7353,  -4.9236,  -5.1048,  ...,  -8.8734,  -8.8916,  -8.8550],\n",
              "        [ -1.3056,  -5.3870,  -5.4945,  ...,  -9.4895,  -9.5039,  -9.4958],\n",
              "        [ -2.7649,  -7.2201,  -9.0916,  ..., -11.3106, -11.3414, -11.2702],\n",
              "        ...,\n",
              "        [ -0.0768,  -4.8210,  -4.4374,  ...,  -8.0483,  -8.0502,  -7.9903],\n",
              "        [ -2.7347,  -5.3650,  -7.2549,  ..., -10.0498, -10.0661,  -9.9886],\n",
              "        [ -1.0991,  -4.2569,  -6.1267,  ...,  -8.6882,  -8.6889,  -8.6272]],\n",
              "       device='cuda:0'), hidden_states=None, attentions=None)"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "start_logits = outputs.start_logits.cpu().numpy()\n",
        "end_logits = outputs.end_logits.cpu().numpy()"
      ],
      "metadata": {
        "id": "DvrgpQOkmBZ_"
      },
      "id": "DvrgpQOkmBZ_",
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "small_validation_processed['sample_id'][:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R9zuq_QpmBtS",
        "outputId": "05458b2e-67c5-4238-e653-1c6cd95823d2"
      },
      "id": "R9zuq_QpmBtS",
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['56be4db0acb8001400a502ec',\n",
              " '56be4db0acb8001400a502ed',\n",
              " '56be4db0acb8001400a502ee',\n",
              " '56be4db0acb8001400a502ef',\n",
              " '56be4db0acb8001400a502f0']"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(validation_dataset['sample_id'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7NE115-wmCAT",
        "outputId": "795580f0-e61b-4011-c376-0e9c23185be4"
      },
      "id": "7NE115-wmCAT",
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10822"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(set(validation_dataset['sample_id']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jsf4WXLtmQzR",
        "outputId": "8a278996-849d-4359-b43d-aea465d9ae16"
      },
      "id": "Jsf4WXLtmQzR",
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10570"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# example: {'56be4db0acb8001400a502ec': [0, 1, 2, 3], ...}\n",
        "sample_id2idxs = {}\n",
        "for i, id_ in enumerate(small_validation_processed['sample_id']):\n",
        "  if id_ not in sample_id2idxs:\n",
        "    sample_id2idxs[id_] = [i]\n",
        "  else:\n",
        "    print(\"here\")\n",
        "    sample_id2idxs[id_].append(i)"
      ],
      "metadata": {
        "id": "OPu8upSemTsD"
      },
      "id": "OPu8upSemTsD",
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "start_logits.shape, end_logits.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qyg45owAmXQU",
        "outputId": "0a87dc7b-843c-4c1a-cbd0-4bf20d3bfea7"
      },
      "id": "qyg45owAmXQU",
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((100, 384), (100, 384))"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# reminder of how to find indices with the largest values\n",
        "(-start_logits[0]).argsort()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vJjPQq1LmXkG",
        "outputId": "ac5b2265-7c2e-411b-a1e0-56ef0841fe90"
      },
      "id": "vJjPQq1LmXkG",
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 46,  57,  47,  38,  39,  58,  50,  43,  45,  54,  56,  49,  13,\n",
              "        42,  40,  35,  27,  31,  48,  41,  53,  44,  37,  59,  78,  15,\n",
              "         0,  52,  24,  65,  81,  70,  18,  51,  55,  26,  69,  29,  28,\n",
              "        75,  61,  64,  23,  36,  32,  11, 101,  62,  66,  34,  95,  30,\n",
              "        63,  21,  19,  20,  17,  14,  22,  33,  68,  87, 171,  12,  76,\n",
              "        71,  73,  92, 110,  84, 151,   1,  74,   2,   6,  16,  80,  79,\n",
              "       105,  98,  10,  96, 136, 169, 106, 100,  93, 165,  67, 109,   8,\n",
              "        90,   3, 115,  60,   5,  97,   7, 103, 102,  86,  72, 111,  89,\n",
              "       108,   4,  88,  25, 132,  77, 123, 150, 124, 153,  83, 118,  82,\n",
              "        85, 107, 114, 143, 164, 137, 130, 166, 159, 131,  91,   9, 144,\n",
              "       139, 160,  94, 141, 128, 112, 134, 152, 170, 154, 117, 127, 104,\n",
              "       140, 157, 155, 133, 145, 119, 162, 138, 135, 156, 167, 168, 126,\n",
              "       148, 163, 161, 116,  99, 120, 142, 158, 125, 146, 113, 121, 147,\n",
              "       149, 129, 122, 311, 312, 304, 309, 313, 310, 300, 307, 316, 308,\n",
              "       314, 306, 317, 320, 319, 321, 291, 318, 301, 305, 287, 270, 315,\n",
              "       295, 289, 294, 251, 333, 303, 269, 299, 274, 265, 298, 176, 175,\n",
              "       338, 292, 323, 322, 290, 252, 296, 229, 177, 302, 297, 186, 245,\n",
              "       250, 283, 174, 256, 337, 266, 190, 293, 286, 264, 288, 331, 327,\n",
              "       234, 237, 227, 284, 255, 326, 276, 272, 233, 346, 191, 230, 218,\n",
              "       232, 179, 285, 273, 173, 187, 239, 332, 172, 267, 329, 238, 253,\n",
              "       334, 214, 192, 325, 278, 350, 259, 281, 268, 185, 254, 271, 279,\n",
              "       342, 345, 343, 181, 335, 183, 189, 260, 341, 275, 178, 228, 210,\n",
              "       324, 277, 212, 348, 209, 336, 261, 240, 249, 246, 194, 257, 182,\n",
              "       377, 258, 196, 195, 248, 188, 339, 197, 213, 378, 263, 208, 201,\n",
              "       205, 200, 225, 211, 282, 236, 204, 347, 203, 262, 223, 193, 330,\n",
              "       199, 202, 349, 184, 180, 351, 340, 226, 224, 243, 217, 372, 244,\n",
              "       241, 207, 235, 344, 215, 367, 247, 368, 382, 352, 379, 353, 221,\n",
              "       376, 231, 380, 220, 371, 366, 242, 219, 381, 206, 375, 369, 216,\n",
              "       198, 355, 383, 280, 328, 222, 358, 373, 357, 363, 356, 374, 354,\n",
              "       359, 365, 370, 364, 362, 361, 360])"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "start_logits[0][(-start_logits[0]).argsort()]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pJJyO9u2mX6q",
        "outputId": "6a507dd9-322e-45a4-a417-4a2dae2b0a23"
      },
      "id": "pJJyO9u2mX6q",
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([10.694445  ,  9.803685  ,  4.459973  ,  4.400487  ,  2.9437785 ,\n",
              "        2.7017367 ,  2.0126448 ,  1.5780739 ,  0.52237445,  0.02073721,\n",
              "       -0.02802688, -0.04971648, -0.38573122, -0.6945363 , -0.7979508 ,\n",
              "       -0.86780477, -0.87220925, -1.3516886 , -1.3703715 , -1.3878827 ,\n",
              "       -1.5135094 , -1.7355472 , -1.8827027 , -1.8932863 , -1.9078972 ,\n",
              "       -1.9304978 , -2.2607322 , -2.2983866 , -2.3069332 , -2.5027428 ,\n",
              "       -2.510063  , -2.530842  , -2.5399983 , -2.6718144 , -2.732354  ,\n",
              "       -2.7710216 , -2.7713673 , -2.9521358 , -3.0604653 , -3.1706066 ,\n",
              "       -3.204542  , -3.569336  , -3.5798059 , -3.6668851 , -3.7250628 ,\n",
              "       -3.7498565 , -3.7632205 , -3.996814  , -4.0113316 , -4.0688004 ,\n",
              "       -4.0944853 , -4.195475  , -4.2383103 , -4.3323617 , -4.352419  ,\n",
              "       -4.3879614 , -4.38861   , -4.396615  , -4.6790547 , -4.7030315 ,\n",
              "       -4.7757587 , -4.7778134 , -4.788218  , -4.7882495 , -4.8221273 ,\n",
              "       -4.872539  , -4.8849363 , -4.8981495 , -5.072096  , -5.10788   ,\n",
              "       -5.1486406 , -5.178329  , -5.191211  , -5.2709002 , -5.3146424 ,\n",
              "       -5.3770766 , -5.5316567 , -5.571128  , -5.6498227 , -5.661312  ,\n",
              "       -5.6778703 , -5.6986046 , -5.751567  , -5.842644  , -5.8621545 ,\n",
              "       -5.9076943 , -5.9093847 , -5.9444485 , -5.996893  , -6.005829  ,\n",
              "       -6.047037  , -6.0640035 , -6.085876  , -6.1005545 , -6.224175  ,\n",
              "       -6.2670965 , -6.2752924 , -6.3032937 , -6.31342   , -6.328805  ,\n",
              "       -6.3306923 , -6.4014874 , -6.4204855 , -6.4361095 , -6.437409  ,\n",
              "       -6.450712  , -6.53143   , -6.5530505 , -6.563022  , -6.668796  ,\n",
              "       -6.7266903 , -6.742629  , -6.744297  , -6.745856  , -6.8108754 ,\n",
              "       -6.921636  , -6.949301  , -6.990772  , -6.9987435 , -7.162264  ,\n",
              "       -7.167353  , -7.1756635 , -7.180565  , -7.1967816 , -7.243593  ,\n",
              "       -7.2733436 , -7.2769523 , -7.3002205 , -7.300931  , -7.3218613 ,\n",
              "       -7.3976803 , -7.4330378 , -7.524845  , -7.5272303 , -7.5322757 ,\n",
              "       -7.573714  , -7.5982127 , -7.658098  , -7.6597095 , -7.7155743 ,\n",
              "       -7.718405  , -7.7400193 , -7.7546544 , -7.885649  , -7.8937654 ,\n",
              "       -7.894368  , -7.938035  , -7.958206  , -8.037518  , -8.059216  ,\n",
              "       -8.063911  , -8.104637  , -8.117334  , -8.138481  , -8.145774  ,\n",
              "       -8.221222  , -8.274247  , -8.292227  , -8.293207  , -8.316828  ,\n",
              "       -8.317498  , -8.334003  , -8.46651   , -8.500584  , -8.502033  ,\n",
              "       -8.591039  , -8.612478  , -8.621495  , -8.6252165 , -8.62546   ,\n",
              "       -8.814265  , -9.039057  , -9.421061  , -9.434792  , -9.4414625 ,\n",
              "       -9.444372  , -9.449848  , -9.450177  , -9.450438  , -9.451044  ,\n",
              "       -9.452064  , -9.452417  , -9.452519  , -9.454133  , -9.456526  ,\n",
              "       -9.458107  , -9.458341  , -9.458446  , -9.458754  , -9.460873  ,\n",
              "       -9.462076  , -9.462511  , -9.462944  , -9.463792  , -9.463905  ,\n",
              "       -9.465524  , -9.466457  , -9.468561  , -9.468853  , -9.468954  ,\n",
              "       -9.469498  , -9.469519  , -9.470058  , -9.470969  , -9.471138  ,\n",
              "       -9.471284  , -9.47136   , -9.471792  , -9.471888  , -9.472047  ,\n",
              "       -9.472694  , -9.472961  , -9.47371   , -9.475201  , -9.4766035 ,\n",
              "       -9.476761  , -9.476779  , -9.4774065 , -9.478309  , -9.478877  ,\n",
              "       -9.479751  , -9.479915  , -9.480066  , -9.480646  , -9.481189  ,\n",
              "       -9.481474  , -9.48152   , -9.481533  , -9.481612  , -9.48179   ,\n",
              "       -9.482165  , -9.482849  , -9.483409  , -9.484575  , -9.484707  ,\n",
              "       -9.484897  , -9.485176  , -9.485302  , -9.485718  , -9.48596   ,\n",
              "       -9.486807  , -9.486976  , -9.487629  , -9.487733  , -9.487908  ,\n",
              "       -9.487989  , -9.488306  , -9.488396  , -9.48859   , -9.488794  ,\n",
              "       -9.488956  , -9.489108  , -9.489487  , -9.489674  , -9.490006  ,\n",
              "       -9.490808  , -9.490833  , -9.490876  , -9.4909    , -9.491136  ,\n",
              "       -9.491258  , -9.49171   , -9.49203   , -9.492166  , -9.492534  ,\n",
              "       -9.492819  , -9.493566  , -9.493645  , -9.493655  , -9.494009  ,\n",
              "       -9.494032  , -9.494384  , -9.495204  , -9.495423  , -9.496533  ,\n",
              "       -9.496601  , -9.497125  , -9.49753   , -9.4975605 , -9.49757   ,\n",
              "       -9.497612  , -9.497622  , -9.498015  , -9.498126  , -9.498631  ,\n",
              "       -9.498655  , -9.498768  , -9.499587  , -9.500014  , -9.500341  ,\n",
              "       -9.50042   , -9.500582  , -9.5009775 , -9.500998  , -9.50117   ,\n",
              "       -9.501225  , -9.501287  , -9.501437  , -9.501509  , -9.501883  ,\n",
              "       -9.502013  , -9.502524  , -9.502687  , -9.503571  , -9.503639  ,\n",
              "       -9.503665  , -9.504168  , -9.504552  , -9.505051  , -9.505538  ,\n",
              "       -9.506176  , -9.506638  , -9.5066805 , -9.506758  , -9.506831  ,\n",
              "       -9.507124  , -9.507556  , -9.5077305 , -9.507984  , -9.508048  ,\n",
              "       -9.508078  , -9.508736  , -9.508773  , -9.50886   , -9.509268  ,\n",
              "       -9.509509  , -9.509532  , -9.510821  , -9.511501  , -9.512038  ,\n",
              "       -9.512431  , -9.512821  , -9.513132  , -9.513145  , -9.513196  ,\n",
              "       -9.513245  , -9.513383  , -9.514933  , -9.5154295 , -9.515567  ,\n",
              "       -9.516188  , -9.516245  , -9.516346  , -9.51638   , -9.516658  ,\n",
              "       -9.517014  , -9.518301  , -9.518472  , -9.518793  , -9.519091  ,\n",
              "       -9.520803  , -9.521007  , -9.521188  , -9.52123   , -9.522545  ,\n",
              "       -9.522749  , -9.522892  , -9.523227  , -9.523898  , -9.524339  ,\n",
              "       -9.525378  , -9.526041  , -9.52703   , -9.528465  , -9.528533  ,\n",
              "       -9.528625  , -9.528757  , -9.529464  , -9.529711  , -9.531369  ,\n",
              "       -9.532368  , -9.532749  , -9.535536  , -9.536652  , -9.537719  ,\n",
              "       -9.538665  , -9.539045  , -9.539342  , -9.540272  , -9.541709  ,\n",
              "       -9.548323  , -9.554484  , -9.557686  , -9.567405  ], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# reminder: in offset_mapping we store None everywhere except the context window\n",
        "# in the context window we store tuples for each token containing:\n",
        "# (start_character_position, end_character_position)\n",
        "small_validation_processed['offset_mapping'][0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iO6DOlSEmYQp",
        "outputId": "82c12f5c-cecf-4236-83d7-ae3445eead96"
      },
      "id": "iO6DOlSEmYQp",
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " [0, 5],\n",
              " [6, 10],\n",
              " [11, 13],\n",
              " [14, 17],\n",
              " [18, 20],\n",
              " [21, 29],\n",
              " [30, 38],\n",
              " [39, 43],\n",
              " [44, 46],\n",
              " [47, 56],\n",
              " [57, 60],\n",
              " [61, 69],\n",
              " [70, 72],\n",
              " [73, 76],\n",
              " [77, 85],\n",
              " [86, 94],\n",
              " [95, 101],\n",
              " [102, 103],\n",
              " [103, 106],\n",
              " [106, 107],\n",
              " [108, 111],\n",
              " [112, 115],\n",
              " [116, 120],\n",
              " [121, 127],\n",
              " [127, 128],\n",
              " [129, 132],\n",
              " [133, 141],\n",
              " [142, 150],\n",
              " [151, 161],\n",
              " [162, 163],\n",
              " [163, 166],\n",
              " [166, 167],\n",
              " [168, 176],\n",
              " [177, 183],\n",
              " [184, 191],\n",
              " [192, 200],\n",
              " [201, 204],\n",
              " [205, 213],\n",
              " [214, 222],\n",
              " [223, 233],\n",
              " [234, 235],\n",
              " [235, 238],\n",
              " [238, 239],\n",
              " [240, 248],\n",
              " [249, 257],\n",
              " [258, 266],\n",
              " [267, 269],\n",
              " [269, 270],\n",
              " [270, 272],\n",
              " [273, 275],\n",
              " [276, 280],\n",
              " [281, 286],\n",
              " [287, 292],\n",
              " [293, 298],\n",
              " [299, 303],\n",
              " [304, 309],\n",
              " [309, 310],\n",
              " [311, 314],\n",
              " [315, 319],\n",
              " [320, 323],\n",
              " [324, 330],\n",
              " [331, 333],\n",
              " [334, 342],\n",
              " [343, 344],\n",
              " [344, 345],\n",
              " [346, 350],\n",
              " [350, 351],\n",
              " [352, 354],\n",
              " [355, 359],\n",
              " [359, 360],\n",
              " [360, 361],\n",
              " [362, 369],\n",
              " [370, 372],\n",
              " [373, 376],\n",
              " [377, 380],\n",
              " [381, 390],\n",
              " [391, 394],\n",
              " [395, 399],\n",
              " [400, 402],\n",
              " [403, 408],\n",
              " [409, 414],\n",
              " [414, 415],\n",
              " [416, 426],\n",
              " [426, 427],\n",
              " [428, 430],\n",
              " [431, 435],\n",
              " [436, 439],\n",
              " [440, 443],\n",
              " [444, 448],\n",
              " [449, 454],\n",
              " [455, 459],\n",
              " [459, 460],\n",
              " [461, 464],\n",
              " [465, 471],\n",
              " [472, 482],\n",
              " [483, 486],\n",
              " [487, 488],\n",
              " [488, 494],\n",
              " [495, 506],\n",
              " [506, 507],\n",
              " [508, 512],\n",
              " [513, 520],\n",
              " [521, 525],\n",
              " [525, 526],\n",
              " [526, 532],\n",
              " [533, 544],\n",
              " [544, 545],\n",
              " [546, 548],\n",
              " [549, 553],\n",
              " [554, 556],\n",
              " [557, 568],\n",
              " [569, 571],\n",
              " [571, 573],\n",
              " [573, 579],\n",
              " [580, 583],\n",
              " [584, 593],\n",
              " [594, 596],\n",
              " [597, 603],\n",
              " [604, 608],\n",
              " [609, 614],\n",
              " [615, 619],\n",
              " [620, 624],\n",
              " [625, 629],\n",
              " [630, 635],\n",
              " [636, 637],\n",
              " [637, 640],\n",
              " [640, 644],\n",
              " [645, 646],\n",
              " [646, 651],\n",
              " [652, 657],\n",
              " [658, 661],\n",
              " [662, 666],\n",
              " [667, 672],\n",
              " [673, 677],\n",
              " [678, 682],\n",
              " [683, 688],\n",
              " [689, 691],\n",
              " [692, 693],\n",
              " [693, 698],\n",
              " [699, 703],\n",
              " [704, 705],\n",
              " [705, 706],\n",
              " [706, 707],\n",
              " [707, 708],\n",
              " [709, 711],\n",
              " [712, 716],\n",
              " [717, 720],\n",
              " [721, 725],\n",
              " [726, 731],\n",
              " [732, 743],\n",
              " [744, 751],\n",
              " [752, 755],\n",
              " [756, 762],\n",
              " [763, 764],\n",
              " [764, 767],\n",
              " [767, 771],\n",
              " [772, 774],\n",
              " [774, 775],\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None]"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n_largest = 20\n",
        "max_answer_length = 30\n",
        "predicted_answers = []\n",
        "\n",
        "# we are looping through the original (untokenized) dataset\n",
        "# because we need to grab the answer from the original string context\n",
        "for sample in small_validation_dataset:\n",
        "  sample_id = sample['id']\n",
        "  context = sample['context']\n",
        "\n",
        "  # update these as we loop through candidate answers\n",
        "  best_score = float('-inf')\n",
        "  best_answer = None\n",
        "\n",
        "  # now loop through the *expanded* input samples (fixed size context windows)\n",
        "  # from here we will pick the highest probability start/end combination\n",
        "  for idx in sample_id2idxs[sample_id]:\n",
        "    start_logit = start_logits[idx] # (384,) vector\n",
        "    end_logit = end_logits[idx] # (384,) vector\n",
        "    offsets = small_validation_processed[idx]['offset_mapping']\n",
        "\n",
        "    start_indices = (-start_logit).argsort()\n",
        "    end_indices = (-end_logit).argsort()\n",
        "\n",
        "    for start_idx in start_indices[:n_largest]:\n",
        "      for end_idx in end_indices[:n_largest]:\n",
        "\n",
        "        # skip answers not contained in context window\n",
        "        # recall: we set entries not pertaining to context to None earlier\n",
        "        if offsets[start_idx] is None or offsets[end_idx] is None:\n",
        "          continue\n",
        "\n",
        "        # skip answers where end < start\n",
        "        if end_idx < start_idx:\n",
        "          continue\n",
        "\n",
        "        # skip answers that are too long\n",
        "        if end_idx - start_idx + 1 > max_answer_length:\n",
        "          continue\n",
        "\n",
        "        # see theory lecture for score calculation\n",
        "        score = start_logit[start_idx] + end_logit[end_idx]\n",
        "        if score > best_score:\n",
        "          best_score = score\n",
        "\n",
        "          # find positions of start and end characters\n",
        "          # recall: offsets contains tuples for each token:\n",
        "          # (start_char, end_char)\n",
        "          first_ch = offsets[start_idx][0]\n",
        "          last_ch = offsets[end_idx][1]\n",
        "\n",
        "          best_answer = context[first_ch:last_ch]\n",
        "\n",
        "  # save best answer\n",
        "  predicted_answers.append({'id': sample_id, 'prediction_text': best_answer})"
      ],
      "metadata": {
        "id": "n9LrYqL8mYjp"
      },
      "id": "n9LrYqL8mYjp",
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "small_validation_dataset['answers'][0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hZpjC-cSmY3i",
        "outputId": "63cf4ec9-6bbf-4887-977a-150403ebeddd"
      },
      "id": "hZpjC-cSmY3i",
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'text': ['Denver Broncos', 'Denver Broncos', 'Denver Broncos'],\n",
              " 'answer_start': [177, 177, 177]}"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# now test it!\n",
        "\n",
        "true_answers = [\n",
        "  {'id': x['id'], 'answers': x['answers']} for x in small_validation_dataset\n",
        "]\n",
        "metric.compute(predictions=predicted_answers, references=true_answers)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wAurpsw4mZUo",
        "outputId": "bb1d6b9f-4f40-47ea-a88d-31dbacca0c8d"
      },
      "id": "wAurpsw4mZUo",
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'exact_match': 83.0, 'f1': 88.25000000000004}"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# now let's define a full compute_metrics function\n",
        "# note: this will NOT be called from the trainer\n",
        "\n",
        "from tqdm.autonotebook import tqdm\n",
        "\n",
        "def compute_metrics(start_logits, end_logits, processed_dataset, orig_dataset):\n",
        "  # map sample_id ('56be4db0acb8001400a502ec') to row indices of processed data\n",
        "  sample_id2idxs = {}\n",
        "  for i, id_ in enumerate(processed_dataset['sample_id']):\n",
        "    if id_ not in sample_id2idxs:\n",
        "      sample_id2idxs[id_] = [i]\n",
        "    else:\n",
        "      sample_id2idxs[id_].append(i)\n",
        "\n",
        "  predicted_answers = []\n",
        "  for sample in tqdm(orig_dataset):\n",
        "\n",
        "    sample_id = sample['id']\n",
        "    context = sample['context']\n",
        "\n",
        "    # update these as we loop through candidate answers\n",
        "    best_score = float('-inf')\n",
        "    best_answer = None\n",
        "\n",
        "    # now loop through the *expanded* input samples (fixed size context windows)\n",
        "    # from here we will pick the highest probability start/end combination\n",
        "    for idx in sample_id2idxs[sample_id]:\n",
        "      start_logit = start_logits[idx] # (T,) vector\n",
        "      end_logit = end_logits[idx] # (T,) vector\n",
        "\n",
        "      # note: do NOT do the reverse: ['offset_mapping'][idx]\n",
        "      offsets = processed_dataset[idx]['offset_mapping']\n",
        "\n",
        "      start_indices = (-start_logit).argsort()\n",
        "      end_indices = (-end_logit).argsort()\n",
        "\n",
        "      for start_idx in start_indices[:n_largest]:\n",
        "        for end_idx in end_indices[:n_largest]:\n",
        "\n",
        "          # skip answers not contained in context window\n",
        "          # recall: we set entries not pertaining to context to None earlier\n",
        "          if offsets[start_idx] is None or offsets[end_idx] is None:\n",
        "            continue\n",
        "\n",
        "          # skip answers where end < start\n",
        "          if end_idx < start_idx:\n",
        "            continue\n",
        "\n",
        "          # skip answers that are too long\n",
        "          if end_idx - start_idx + 1 > max_answer_length:\n",
        "            continue\n",
        "\n",
        "          # see theory lecture for score calculation\n",
        "          score = start_logit[start_idx] + end_logit[end_idx]\n",
        "          if score > best_score:\n",
        "            best_score = score\n",
        "\n",
        "            # find positions of start and end characters\n",
        "            # recall: offsets contains tuples for each token:\n",
        "            # (start_char, end_char)\n",
        "            first_ch = offsets[start_idx][0]\n",
        "            last_ch = offsets[end_idx][1]\n",
        "\n",
        "            best_answer = context[first_ch:last_ch]\n",
        "\n",
        "    # save best answer\n",
        "    predicted_answers.append({'id': sample_id, 'prediction_text': best_answer})\n",
        "\n",
        "  # compute the metrics\n",
        "  true_answers = [\n",
        "    {'id': x['id'], 'answers': x['answers']} for x in orig_dataset\n",
        "  ]\n",
        "  return metric.compute(predictions=predicted_answers, references=true_answers)"
      ],
      "metadata": {
        "id": "KAps0FNDm3qX"
      },
      "id": "KAps0FNDm3qX",
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# run our function on the same mini dataset as before\n",
        "compute_metrics(\n",
        "    start_logits,\n",
        "    end_logits,\n",
        "    small_validation_processed,\n",
        "    small_validation_dataset,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "10b401428a2c499a952ee696a2f3350a",
            "c8ffed0f0578409c8e02657849ea5cec",
            "75b994a790024314b2906ec485107501",
            "ddcdd9c8372a44669659759f240df6dc",
            "610ad44c8b9e4f31879be0ade458fd98",
            "d51e84d7e42b47b4884b05d08cbc932a",
            "6673f622d43f48cc836dc0cec2e07570",
            "5cf59b986a274601b12261875448551c",
            "ec74a110e6bf46dfb20af9c63006852e",
            "c86b8b7f5a6f429daaef1a79a2092a75",
            "e6eb54c45d224a088d413a57349717fa"
          ]
        },
        "id": "i4mYvSJFm3_e",
        "outputId": "b4ca78e8-1adb-4979-841b-123acbd906db"
      },
      "id": "i4mYvSJFm3_e",
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/100 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "10b401428a2c499a952ee696a2f3350a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'exact_match': 83.0, 'f1': 88.25000000000004}"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# now load the model we want to fine-tune\n",
        "model = AutoModelForQuestionAnswering.from_pretrained(model_checkpoint)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qDMD0Qx2m4WN",
        "outputId": "a9fbb437-e5ac-43d1-b3e5-8d7a6b3c2f16"
      },
      "id": "qDMD0Qx2m4WN",
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of DistilBertForQuestionAnswering were not initialized from the model checkpoint at distilbert-base-cased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install accelerate -U"
      ],
      "metadata": {
        "id": "hcvwIQqNnfcq"
      },
      "id": "hcvwIQqNnfcq",
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TrainingArguments\n",
        "\n",
        "args = TrainingArguments(\n",
        "    \"finetuned-squad\",\n",
        "    evaluation_strategy=\"no\",\n",
        "    save_strategy=\"epoch\",\n",
        "    learning_rate=2e-5,\n",
        "    num_train_epochs=3,\n",
        "    weight_decay=0.01,\n",
        "    fp16=True,\n",
        ")"
      ],
      "metadata": {
        "id": "e09TH711m4sY"
      },
      "id": "e09TH711m4sY",
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import Trainer\n",
        "\n",
        "# takes ~2.5h with bert on full dataset\n",
        "# ~1h 15min with distilbert\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=args,\n",
        "    train_dataset=train_dataset,\n",
        "    # train_dataset=train_dataset.shuffle(seed=42).select(range(1_000)),\n",
        "    eval_dataset=validation_dataset,\n",
        "    tokenizer=tokenizer,\n",
        ")\n",
        "trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        },
        "id": "qIz1LwR-m5KF",
        "outputId": "1dd08444-aecd-47f7-d8e4-3213f3e566fb"
      },
      "id": "qIz1LwR-m5KF",
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1085' max='33276' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [ 1085/33276 02:22 < 1:10:22, 7.62 it/s, Epoch 0.10/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>3.245100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>2.286900</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-79-744075dfe46d>\u001b[0m in \u001b[0;36m<cell line: 14>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mtokenizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m )\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1857\u001b[0m                 \u001b[0mhf_hub_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_progress_bars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1858\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1859\u001b[0;31m             return inner_training_loop(\n\u001b[0m\u001b[1;32m   1860\u001b[0m                 \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1861\u001b[0m                 \u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2265\u001b[0m                     \u001b[0;31m# Optimizer step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2266\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2267\u001b[0m                     \u001b[0moptimizer_was_run\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccelerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer_step_was_skipped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2268\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0moptimizer_was_run\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/accelerate/optimizer.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    134\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_optimizer_patched_step_method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclosure\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    137\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/cuda/amp/grad_scaler.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, optimizer, *args, **kwargs)\u001b[0m\n\u001b[1;32m    450\u001b[0m         ), \"No inf checks were recorded for this optimizer.\"\n\u001b[1;32m    451\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 452\u001b[0;31m         \u001b[0mretval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_opt_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    453\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    454\u001b[0m         \u001b[0moptimizer_state\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"stage\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOptState\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSTEPPED\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/cuda/amp/grad_scaler.py\u001b[0m in \u001b[0;36m_maybe_opt_step\u001b[0;34m(self, optimizer, optimizer_state, *args, **kwargs)\u001b[0m\n\u001b[1;32m    348\u001b[0m         \u001b[0mretval\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moptimizer_state\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"found_inf_per_device\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 350\u001b[0;31m             \u001b[0mretval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    351\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mretval\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    352\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/accelerate/optimizer.py\u001b[0m in \u001b[0;36mpatched_step\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    189\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpatched_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0maccelerated_optimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_accelerate_step_called\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 191\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mpatched_step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     73\u001b[0m                 \u001b[0minstance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_step_count\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m                 \u001b[0mwrapped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m             \u001b[0;31m# Note that the returned function here is no longer a bound method,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    383\u001b[0m                             )\n\u001b[1;32m    384\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 385\u001b[0;31m                 \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    386\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_optimizer_step_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36m_use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     74\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_grad_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefaults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'differentiable'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph_break\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph_break\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/optim/adamw.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    185\u001b[0m             )\n\u001b[1;32m    186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m             adamw(\n\u001b[0m\u001b[1;32m    188\u001b[0m                 \u001b[0mparams_with_grad\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m                 \u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/optim/adamw.py\u001b[0m in \u001b[0;36madamw\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, has_complex, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m    337\u001b[0m         \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_single_tensor_adamw\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 339\u001b[0;31m     func(\n\u001b[0m\u001b[1;32m    340\u001b[0m         \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m         \u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/optim/adamw.py\u001b[0m in \u001b[0;36m_multi_tensor_adamw\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable, has_complex)\u001b[0m\n\u001b[1;32m    597\u001b[0m             \u001b[0mstep_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_stack_if_compiling\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mbc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mbc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbias_correction1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 599\u001b[0;31m             \u001b[0mbias_correction2_sqrt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_dispatch_sqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mbc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbias_correction2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    600\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    601\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mamsgrad\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/optim/adamw.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    597\u001b[0m             \u001b[0mstep_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_stack_if_compiling\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mbc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mbc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbias_correction1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 599\u001b[0;31m             \u001b[0mbias_correction2_sqrt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_dispatch_sqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mbc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbias_correction2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    600\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    601\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mamsgrad\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36m_dispatch_sqrt\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[0;31m# For any optimizer with a faster implementation, we attempt to default to the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer_output = trainer.predict(validation_dataset)"
      ],
      "metadata": {
        "id": "h9vGTBQEqMhv"
      },
      "id": "h9vGTBQEqMhv",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(trainer_output)"
      ],
      "metadata": {
        "id": "KGsDY26_qM2A"
      },
      "id": "KGsDY26_qM2A",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer_output"
      ],
      "metadata": {
        "id": "yYnx7TSJqNMO"
      },
      "id": "yYnx7TSJqNMO",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions, _, _ = trainer_output"
      ],
      "metadata": {
        "id": "tfvp_yI5qNff"
      },
      "id": "tfvp_yI5qNff",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions"
      ],
      "metadata": {
        "id": "XEnbWNWPqNzm"
      },
      "id": "XEnbWNWPqNzm",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "start_logits, end_logits = predictions"
      ],
      "metadata": {
        "id": "eeAhGpw3qOMU"
      },
      "id": "eeAhGpw3qOMU",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "compute_metrics(\n",
        "    start_logits,\n",
        "    end_logits,\n",
        "    validation_dataset, # processed\n",
        "    raw_datasets[\"validation\"], # orig\n",
        ")"
      ],
      "metadata": {
        "id": "dA9s0Ur-qasl"
      },
      "id": "dA9s0Ur-qasl",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.save_model('my_saved_model')"
      ],
      "metadata": {
        "id": "IguSJNLkqbAF"
      },
      "id": "IguSJNLkqbAF",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "qa = pipeline(\n",
        "  \"question-answering\",\n",
        "  model='my_saved_model',\n",
        "  device=0,\n",
        ")"
      ],
      "metadata": {
        "id": "Te5FGcp6qbTG"
      },
      "id": "Te5FGcp6qbTG",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "context = \"Today I went to the store to purchase a carton of milk.\"\n",
        "question = \"What did I buy?\"\n",
        "\n",
        "qa(context=context, question=question)"
      ],
      "metadata": {
        "id": "K6fMhszzqbl9"
      },
      "id": "K6fMhszzqbl9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# exercise: try it with bert instead of distilbert for an even higher score!"
      ],
      "metadata": {
        "id": "Ja3J82qfqb6e"
      },
      "id": "Ja3J82qfqb6e",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    },
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "gpuType": "T4"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "3796f3e2592b4a5c97da89079cfc82a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_57ced85810cd4678b912b29a6c276a38",
              "IPY_MODEL_a9e9f71a3fda4439b8dd00f72be86447",
              "IPY_MODEL_d2eaf78f39714cfeb612ddc32a66a094"
            ],
            "layout": "IPY_MODEL_a3ca06abf19248d582890c892fca831c"
          }
        },
        "57ced85810cd4678b912b29a6c276a38": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0d0dc742d89c4665a7dc0ca3c47620a3",
            "placeholder": "​",
            "style": "IPY_MODEL_b8522d46e7954fd2bac1a0bad9e81996",
            "value": "Map: 100%"
          }
        },
        "a9e9f71a3fda4439b8dd00f72be86447": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_384e57c913ed4376adb98a42ab947fd1",
            "max": 10570,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_60f0b2575f834e279baddc07f9df474f",
            "value": 10570
          }
        },
        "d2eaf78f39714cfeb612ddc32a66a094": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b5d22b017271412991f5037ac6b0a019",
            "placeholder": "​",
            "style": "IPY_MODEL_2aaab1720fce418db61544869a19eca1",
            "value": " 10570/10570 [00:09&lt;00:00, 1140.36 examples/s]"
          }
        },
        "a3ca06abf19248d582890c892fca831c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0d0dc742d89c4665a7dc0ca3c47620a3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b8522d46e7954fd2bac1a0bad9e81996": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "384e57c913ed4376adb98a42ab947fd1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "60f0b2575f834e279baddc07f9df474f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b5d22b017271412991f5037ac6b0a019": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2aaab1720fce418db61544869a19eca1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "10b401428a2c499a952ee696a2f3350a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c8ffed0f0578409c8e02657849ea5cec",
              "IPY_MODEL_75b994a790024314b2906ec485107501",
              "IPY_MODEL_ddcdd9c8372a44669659759f240df6dc"
            ],
            "layout": "IPY_MODEL_610ad44c8b9e4f31879be0ade458fd98"
          }
        },
        "c8ffed0f0578409c8e02657849ea5cec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d51e84d7e42b47b4884b05d08cbc932a",
            "placeholder": "​",
            "style": "IPY_MODEL_6673f622d43f48cc836dc0cec2e07570",
            "value": "100%"
          }
        },
        "75b994a790024314b2906ec485107501": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5cf59b986a274601b12261875448551c",
            "max": 100,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ec74a110e6bf46dfb20af9c63006852e",
            "value": 100
          }
        },
        "ddcdd9c8372a44669659759f240df6dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c86b8b7f5a6f429daaef1a79a2092a75",
            "placeholder": "​",
            "style": "IPY_MODEL_e6eb54c45d224a088d413a57349717fa",
            "value": " 100/100 [00:00&lt;00:00, 459.71it/s]"
          }
        },
        "610ad44c8b9e4f31879be0ade458fd98": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d51e84d7e42b47b4884b05d08cbc932a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6673f622d43f48cc836dc0cec2e07570": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5cf59b986a274601b12261875448551c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ec74a110e6bf46dfb20af9c63006852e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c86b8b7f5a6f429daaef1a79a2092a75": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e6eb54c45d224a088d413a57349717fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}