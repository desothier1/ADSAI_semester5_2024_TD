{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "07090841",
      "metadata": {
        "id": "07090841"
      },
      "source": [
        "# Transformers zero shot classification"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##1 zero shot learning pipeline\n",
        "\n",
        "-Install transformers and select T4 GPU<br>\n",
        "-Check cuda device<br>\n",
        "-import numpy, pandas, matplotlib, seaborn<br>\n",
        "-import sklearn.metrics confusion_matrix, classification_report\n"
      ],
      "metadata": {
        "id": "5gHCSjiclmg3"
      },
      "id": "5gHCSjiclmg3"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "875b31a4",
      "metadata": {
        "scrolled": true,
        "id": "875b31a4"
      },
      "outputs": [],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "92154835",
      "metadata": {
        "id": "92154835",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "19212e13-2054-499e-c124-5d909b33c2c4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "import torch\n",
        "torch.cuda.is_available()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "195894dd",
      "metadata": {
        "id": "195894dd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3812d8d9-8150-47af-ef13-2646bddaf9c6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "torch.cuda.current_device()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "07c57cc9",
      "metadata": {
        "id": "07c57cc9"
      },
      "outputs": [],
      "source": [
        "from transformers import pipeline\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sn\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix, classification_report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5ab6d886",
      "metadata": {
        "id": "5ab6d886"
      },
      "outputs": [],
      "source": [
        "classifier = pipeline(\"zero-shot-classification\", device=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###1.1 Zero-shot learning examples"
      ],
      "metadata": {
        "id": "5NJ3coxmmzDf"
      },
      "id": "5NJ3coxmmzDf"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1d5cb7cc",
      "metadata": {
        "id": "1d5cb7cc"
      },
      "outputs": [],
      "source": [
        "classifier(\"This is a great movie.\", candidate_labels=['positive','negative','neutral'])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "-Use the classifier and create example output for a positive, negative and about 5 neutral sentiments."
      ],
      "metadata": {
        "id": "UKsT5kE5niXE"
      },
      "id": "UKsT5kE5niXE"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9456d144",
      "metadata": {
        "id": "9456d144"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "insert code below\n",
        "\"\"\"\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##2 Sentiment zero-shot learning"
      ],
      "metadata": {
        "id": "R2zkv_O3pjwu"
      },
      "id": "R2zkv_O3pjwu"
    },
    {
      "cell_type": "markdown",
      "source": [
        "-The necessary steps (and the code to use) are very similar to the sentiment prediction task, but this time we use also the neutral class, next to the positive and negative class.<br>\n",
        "-With zero shot learning, the classifier might learn to classify for the neutral class."
      ],
      "metadata": {
        "id": "k0x7SVMSbhoD"
      },
      "id": "k0x7SVMSbhoD"
    },
    {
      "cell_type": "markdown",
      "source": [
        "###2.1 Prepare data set"
      ],
      "metadata": {
        "id": "oRc88AbezvGf"
      },
      "id": "oRc88AbezvGf"
    },
    {
      "cell_type": "markdown",
      "source": [
        "-Read the Tweets.csv dataset and call it df."
      ],
      "metadata": {
        "id": "YLcAere06Cue"
      },
      "id": "YLcAere06Cue"
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"Tweets.csv\")"
      ],
      "metadata": {
        "id": "wT9lTgZIqpU8"
      },
      "id": "wT9lTgZIqpU8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "BEbMBvnWb0lS"
      },
      "id": "BEbMBvnWb0lS"
    },
    {
      "cell_type": "markdown",
      "source": [
        "-This time, Keep the neutral sentiments.<br>\n",
        "-Select the same 500 randomized (random_state=42) positive, 500 negative instances and 500 neutral sentiments."
      ],
      "metadata": {
        "id": "94ijkju16Kgm"
      },
      "id": "94ijkju16Kgm"
    },
    {
      "cell_type": "code",
      "source": [
        "#select indices randomly with random_state=42, for positive, negative and neutral labels\n",
        "negative_indices = \"\"\"insert your code\"\"\"\n",
        "positive_indices = \"\"\"insert your code\"\"\"\n",
        "neutral_indices = \"\"\"insert your code\"\"\"\n",
        "\n",
        "# Create separate DataFrames for selected positive, negative and neutral labels\n",
        "df_positive = \"\"\"insert your code\"\"\"\n",
        "df_negative = \"\"\"insert your code\"\"\"\n",
        "df_neutral = \"\"\"insert your code\"\"\"\n",
        "\n",
        "# Concatenate the DataFrames to combine them\n",
        "df = \"\"\"insert your code\"\"\"\n"
      ],
      "metadata": {
        "id": "dGeBO1m6quoP"
      },
      "id": "dGeBO1m6quoP",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "-Check the last 100 instances"
      ],
      "metadata": {
        "id": "SRdQobiL6b2w"
      },
      "id": "SRdQobiL6b2w"
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "insert your code\n",
        "\"\"\"\n"
      ],
      "metadata": {
        "id": "4VooiHbmreEB"
      },
      "id": "4VooiHbmreEB",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "-count label values in the df data set for the column 'airline_sentiment'"
      ],
      "metadata": {
        "id": "t_9TZZno7giQ"
      },
      "id": "t_9TZZno7giQ"
    },
    {
      "cell_type": "code",
      "source": [
        "df['airline_sentiment']\"\"\"insert your code\"\"\""
      ],
      "metadata": {
        "id": "yc4iqHIXrBEg"
      },
      "id": "yc4iqHIXrBEg",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "-create a list of unique labels with the name 'labels' for the label values of the df data set column airline_sentiment."
      ],
      "metadata": {
        "id": "8AYB9tZ8-noL"
      },
      "id": "8AYB9tZ8-noL"
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "labels=\"\"\"insert code\"\"\"\n",
        "labels"
      ],
      "metadata": {
        "id": "0UaW3acerEFO"
      },
      "id": "0UaW3acerEFO",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###2.2 Predict"
      ],
      "metadata": {
        "id": "mjdu2t5mz1si"
      },
      "id": "mjdu2t5mz1si"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Modify the code: <br>\n",
        "classifier(\"This is a great movie.\", candidate_labels=['positive','negative','neutral']) <br>\n",
        "\n",
        "-Replace \"This is a great movie\", by the text column of the df data set, and convert it to a list.<br>\n",
        "-Replace ['positive','negative','neutral'] labels by the unique labels list 'labels'.<br>\n",
        "-the output should be stored in the list 'preds'.<br>\n",
        "\n",
        "-Output format example:<br>\n",
        "\n",
        "{'sequence': '@SouthwestAir thanks for your excellent response time and assistance! All set :)',\n",
        " 'labels': ['positive', 'neutral', 'negative'],\n",
        " 'scores': [0.9702585935592651, 0.020787056535482407, 0.008954361081123352]},<br>\n",
        "..."
      ],
      "metadata": {
        "id": "A2aAra5JBxEY"
      },
      "id": "A2aAra5JBxEY"
    },
    {
      "cell_type": "code",
      "source": [
        "preds = classifier(\"\"\"insert code\"\"\")"
      ],
      "metadata": {
        "id": "6KEEQ8oKzd1R"
      },
      "id": "6KEEQ8oKzd1R",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "-Check a negative, positive, and neutral label prediction."
      ],
      "metadata": {
        "id": "P4BkGqFCCdlj"
      },
      "id": "P4BkGqFCCdlj"
    },
    {
      "cell_type": "markdown",
      "source": [
        "-Check a negative target example"
      ],
      "metadata": {
        "id": "astDjL2Z4Jj9"
      },
      "id": "astDjL2Z4Jj9"
    },
    {
      "cell_type": "code",
      "source": [
        "#current output is only an example\n",
        "\"\"\"insert code\"\"\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z_66WoPkzeIc",
        "outputId": "2bc3a212-4a64-4128-b236-ab4e7c360e88"
      },
      "id": "z_66WoPkzeIc",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'sequence': '@united gate C 24 IAD. U released passengers to board w/others deplaning .50 peopleOn bridge while next flight  board http://t.co/HfoF33iyhi',\n",
              " 'labels': ['positive', 'negative', 'neutral'],\n",
              " 'scores': [0.3941085636615753, 0.3191085159778595, 0.28678297996520996]}"
            ]
          },
          "metadata": {},
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "-Check a positive target example"
      ],
      "metadata": {
        "id": "pa4A1vQ14ObZ"
      },
      "id": "pa4A1vQ14ObZ"
    },
    {
      "cell_type": "code",
      "source": [
        "#current output is only an example\n",
        "\"\"\"insert code\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l6AZ0BmevCwL",
        "outputId": "b27020f9-e7bc-44fb-e585-8c46dd128c3c"
      },
      "id": "l6AZ0BmevCwL",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'sequence': \"@AmericanAir Thanks for the quick response - it's appreciated!\",\n",
              " 'labels': ['positive', 'neutral', 'negative'],\n",
              " 'scores': [0.9349985718727112, 0.0407593734562397, 0.024242054671049118]}"
            ]
          },
          "metadata": {},
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "-Check a neutral target example"
      ],
      "metadata": {
        "id": "vYEW5hSY4ThK"
      },
      "id": "vYEW5hSY4ThK"
    },
    {
      "cell_type": "code",
      "source": [
        "#current output is only an example\n",
        "\"\"\"insert code\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Aps8R6CcvLEO",
        "outputId": "408f91f5-6e06-4fad-8df8-cbd9f11a73f3"
      },
      "id": "Aps8R6CcvLEO",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'sequence': '@AmericanAir got a callback at 1 am, took care of it. thanks.',\n",
              " 'labels': ['positive', 'negative', 'neutral'],\n",
              " 'scores': [0.711544394493103, 0.16684234142303467, 0.12161325663328171]}"
            ]
          },
          "metadata": {},
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "-make a list 'predicted_labels' containing the predicted labels with the highest score per case. <br>\n",
        "-For the example: <br>\n",
        "\n",
        "-{'sequence': '@USAirways obviously your corporate definition of PATIENCE needs to be reviewed.',\n",
        " 'labels': ['negative', 'neutral', 'positive'],\n",
        " 'scores': [0.8840194344520569, 0.07365462183952332, 0.042325928807258606]},<br>\n",
        "\n",
        "label with the highest score is here 'negative'.<br>\n",
        "The highest score is each time the first one in the scores list.<br>\n",
        "-Use a list comprehension\n",
        "\n"
      ],
      "metadata": {
        "id": "r3RDtIneFk5o"
      },
      "id": "r3RDtIneFk5o"
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "predicted_labels = [\"\"\"insert code\"\"\"]"
      ],
      "metadata": {
        "id": "_1ivaZbezeai"
      },
      "id": "_1ivaZbezeai",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "-Add the list 'predicted_labels' as a column to the df data set with the name 'predicted_labels'"
      ],
      "metadata": {
        "id": "tvxXYqupGydT"
      },
      "id": "tvxXYqupGydT"
    },
    {
      "cell_type": "code",
      "source": [
        "df['predicted_labels']=predicted_labels"
      ],
      "metadata": {
        "id": "jcvg5ZR57tSU"
      },
      "id": "jcvg5ZR57tSU",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "-Check the first 5 instances in the updated df data set."
      ],
      "metadata": {
        "id": "VU_eIEEUHGK-"
      },
      "id": "VU_eIEEUHGK-"
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"insert code\"\"\""
      ],
      "metadata": {
        "id": "_PO5bywe7vaM"
      },
      "id": "_PO5bywe7vaM",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "-Map the labels: <br>\n",
        " 'positive' to 1 <br>\n",
        " 'negative' to 0 <br>\n",
        " 'neutral' to 2 <br>\n",
        " -for the columns 'airline_sentiment', 'predicted_labels',<br>\n",
        " and store resulting labels,\n",
        " for 'airline_sentiment' in a new column 'target'\n",
        " for 'predicted_labels' in a new column 'prediction' <br>\n",
        "\n",
        " in the df data set"
      ],
      "metadata": {
        "id": "GNlZgRqyJq4a"
      },
      "id": "GNlZgRqyJq4a"
    },
    {
      "cell_type": "code",
      "source": [
        "#complete dictionary target_map with labels as keys (positive, negative, neutral), and numbers as values (1,0,2)\n",
        "target_map = {\"\"\"insert code\"\"\"}\n",
        "df['target']=df['airline_sentiment'].map(target_map)\n",
        "df['prediction']=\"\"\"insert code\"\"\"\n",
        "df['target']\n"
      ],
      "metadata": {
        "id": "ckNDu5zW-Ce0"
      },
      "id": "ckNDu5zW-Ce0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['prediction']"
      ],
      "metadata": {
        "id": "-GK0_5ti-zrn"
      },
      "id": "-GK0_5ti-zrn",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###2.3 Metrics"
      ],
      "metadata": {
        "id": "tZefrzEd2qnA"
      },
      "id": "tZefrzEd2qnA"
    },
    {
      "cell_type": "markdown",
      "source": [
        "-Calculate accuracy"
      ],
      "metadata": {
        "id": "-7IfRWOfZ04d"
      },
      "id": "-7IfRWOfZ04d"
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"insert code\"\"\"\n",
        "\n"
      ],
      "metadata": {
        "id": "lP-y7gI_ze9u"
      },
      "id": "lP-y7gI_ze9u",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "-Calculate precision, recall, F1-score with metrics per sentiment class."
      ],
      "metadata": {
        "id": "7KfwiFG5aO3Q"
      },
      "id": "7KfwiFG5aO3Q"
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"insert code\"\"\""
      ],
      "metadata": {
        "id": "nQuBsEKI2tDO"
      },
      "id": "nQuBsEKI2tDO",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "-Generate a confusion matrix"
      ],
      "metadata": {
        "id": "HAEg77NQaYWk"
      },
      "id": "HAEg77NQaYWk"
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"insert code\"\"\""
      ],
      "metadata": {
        "id": "V5vWcGvlDiM2"
      },
      "id": "V5vWcGvlDiM2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "-Visualize the confusion matrix."
      ],
      "metadata": {
        "id": "jck_DIvoadBS"
      },
      "id": "jck_DIvoadBS"
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def plot_cm(cm):\n",
        "    \"\"\"insert code\"\"\"\n",
        "    df_cm = pd.DataFrame(cm, index=classes, columns=classes)\n",
        "    ax = sn.heatmap(df_cm, annot=True, fmt='g')\n",
        "    ax.set_xlabel(\"Predicted\")\n",
        "    ax.set_ylabel(\"Target\")\n",
        "\n",
        "\n",
        "\"\"\"insert code\"\"\""
      ],
      "metadata": {
        "id": "kyCsjLfQDic7"
      },
      "id": "kyCsjLfQDic7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3 Cosine similarity"
      ],
      "metadata": {
        "id": "P1q7LfAbINKY"
      },
      "id": "P1q7LfAbINKY"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.1 Cosine similarity example"
      ],
      "metadata": {
        "id": "TguII-h-Dmgs"
      },
      "id": "TguII-h-Dmgs"
    },
    {
      "cell_type": "markdown",
      "source": [
        "The next script calculates the cosine similarity between 2 sentences, using sentence transformers.<br>\n",
        "Sentence-Transformers is a state-of-the-art Python framework for embedding sentences. These embeddings can then be used for finding sentences with similar meanings using cosine similarity.<br>\n",
        "Test the script with the current 2 examples, and use other examples."
      ],
      "metadata": {
        "id": "lRAiVcVAXnCv"
      },
      "id": "lRAiVcVAXnCv"
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sentence_transformers\n",
        "from sentence_transformers import SentenceTransformer, util\n",
        "import torch\n",
        "\n",
        "# Load pre-trained Sentence-BERT model\n",
        "model = SentenceTransformer('paraphrase-MiniLM-L6-v2')\n",
        "\n",
        "# Define the sentences\n",
        "sentence1 = 'I feel so good.'\n",
        "sentence2 = 'I feel quite good.'\n",
        "\n",
        "# Get embeddings for sentence 1\n",
        "embeddings1 = model.encode(sentence1, convert_to_tensor=True).unsqueeze(0)\n",
        "\n",
        "# Get embeddings for sentence 2\n",
        "embeddings2 = model.encode(sentence2, convert_to_tensor=True).unsqueeze(0)\n",
        "\n",
        "# Move tensors to GPU if available\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "embeddings1 = embeddings1.to(device)\n",
        "embeddings2 = embeddings2.to(device)\n",
        "\n",
        "# Calculate cosine similarity\n",
        "similarity = util.pytorch_cos_sim(embeddings1, embeddings2)\n",
        "#similarity = cosine_similarity(embeddings1.cpu().numpy(), embeddings2.cpu().numpy())\n",
        "\n",
        "print(f'Cosine Similarity: {similarity[0][0]}')\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "0GV1bEecHyzO"
      },
      "id": "0GV1bEecHyzO",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.2 Cosine similarity: search most similar sentence from a file to a specified user sentence"
      ],
      "metadata": {
        "id": "AJdPp-joD2pM"
      },
      "id": "AJdPp-joD2pM"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Adapt the script below, based on the previous script: <br>\n",
        "-The goal is that you can specify an index from the commandline, the script searches the corresponding sentence, and also searches for the most semantically similar sentence in the data set.<br>\n",
        "-The script reads the disastertweets.csv file into a pandas dataframe.<br>\n",
        "-It reads a number from the commandline that corresponds to the index of an instance in the csv file.<br>\n",
        "-It searches for the semantically closest sentence in the file, of course WITHOUT your input sentence.<br>\n",
        "-As the file is large for colab,  only limit the file to the first 1500 instances.<br>\n",
        "-Insert your code where indicated."
      ],
      "metadata": {
        "id": "8z_z7X9EX7J2"
      },
      "id": "8z_z7X9EX7J2"
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sentence_transformers\n",
        "from sentence_transformers import SentenceTransformer, util\n",
        "import torch\n",
        "import pandas as pd\n",
        "\n",
        "# Load pre-trained Sentence-BERT model\n",
        "model = SentenceTransformer('paraphrase-MiniLM-L6-v2')\n",
        "\n",
        "# Read the pandas dataframe from file disastertweets.csv\n",
        "df_orig = \"\"\"insert code\"\"\"\n",
        "#Select only the first 1500 sentences from df_orig\n",
        "df = \"\"\"insert code\"\"\"\n",
        "\n",
        "# User input for index\n",
        "user_index = int(input(f\"Enter an index between 0 and {len(df) - 1}: \"))\n",
        "\n",
        "# Get the text from the field 'text' from df, at the index, specified by the user, using loc or iloc\n",
        "user_sentence = df.\"\"\"insert code\"\"\"\n",
        "\n",
        "# Remove the user-chosen sentence from the dataframe\n",
        "df = df.drop(index=user_index).reset_index(drop=True)\n",
        "\n",
        "# Encode the user_sentence\n",
        "embeddings_user = model.encode(user_sentence, convert_to_tensor=True).unsqueeze(0)\n",
        "\n",
        "# Initialize variables for closest sentence and similarity\n",
        "closest_similarity = 0\n",
        "closest_sentence = \"\"\n",
        "\n",
        "# Iterate over other sentences in the modified dataframe\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "for index, row in df.iterrows():\n",
        "    # Encode current sentence\n",
        "    embeddings_current = model.encode(row['text'], convert_to_tensor=True).unsqueeze(0)\n",
        "\n",
        "    # Calculate cosine similarity between the sentence specified by the user and the embeddings of the other sentences.\n",
        "    similarity = util.pytorch_cos_sim(\"\"\"insert code\"\"\", embeddings_current.to(device))\n",
        "\n",
        "    # Update closest similarity and sentence\n",
        "    if similarity > closest_similarity:\n",
        "        \"\"\"insert code\"\"\"\n",
        "        closest_sentence = row['text']\n",
        "\n",
        "print(f'Closest Sentence: {closest_sentence}')\n",
        "print(f'User sentence: {user_sentence}')\n",
        "print(f'Cosine Similarity: {closest_similarity.item()}')\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "EOpYkiUfH4vV"
      },
      "id": "EOpYkiUfH4vV",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.3 Cosine similarity: search X most similar sentences from a file to a specified user sentence"
      ],
      "metadata": {
        "id": "hKvnWseGEImy"
      },
      "id": "hKvnWseGEImy"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Adapt the script below, based on the previous script: <br>\n",
        "-The goal is that you can specify an index from the commandline, the script searches the corresponding sentence, and also searches for X (number) of most semantically similar sentences in the data set.<br>\n",
        "-The script reads the disastertweets.csv file into a pandas dataframe.<br>\n",
        "-It reads a number from the commandline that corresponds to the index of an instance in the csv file.<br>\n",
        "-It also reads a number from the commandline that corresponds to the number of most similar sentences to retrieve.<br>\n",
        "-As the file is large for colab,  only limit the file to the first 1500 instances.<br>\n",
        "-Insert your code where indicated."
      ],
      "metadata": {
        "id": "vK-zOdby4jJT"
      },
      "id": "vK-zOdby4jJT"
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sentence_transformers\n",
        "from sentence_transformers import SentenceTransformer, util\n",
        "import torch\n",
        "import pandas as pd\n",
        "\n",
        "# Load pre-trained Sentence-BERT model\n",
        "model = SentenceTransformer('paraphrase-MiniLM-L6-v2')\n",
        "\n",
        "# Read the pandas dataframe from file disastertweets.csv\n",
        "df_orig = \"\"\"insert code\"\"\"\n",
        "#Select only the first 1500 sentences from df_orig\n",
        "df = \"\"\"insert code\"\"\"\n",
        "\n",
        "# User input for index\n",
        "user_index = int(input(f\"Enter an index between 0 and {len(df) - 1}: \"))\n",
        "\n",
        "# Get the text from the field 'text' from df, at the index, specified by the user, using loc or iloc\n",
        "user_sentence = df.\"\"\"insert code\"\"\"\n",
        "\n",
        "# Remove the user-chosen sentence from the dataframe\n",
        "df = df.drop(index=user_index).reset_index(drop=True)\n",
        "\n",
        "# Encode user sentence\n",
        "embeddings_user = model.encode(user_sentence, convert_to_tensor=True).unsqueeze(0)\n",
        "\n",
        "# User input for the NUMBER of most similar sentences to predict\n",
        "num_similar_sentences = \"\"\"insert code\"\"\"(input(\"Enter the number of most similar sentences to predict: \"))\n",
        "\n",
        "# Initialize a list to store top similar sentences and similarity scores\n",
        "top_similar_sentences = []\n",
        "top_similarities = []\n",
        "\n",
        "# Iterate over other sentences in the modified dataframe\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "for index, row in df.iterrows():\n",
        "    # Encode current sentence\n",
        "    embeddings_current = model.encode(row['text'], convert_to_tensor=True).unsqueeze(0)\n",
        "\n",
        "    # Calculate cosine similarity between the sentence specified by the user and the embeddings of the other sentences.\n",
        "    similarity = util.pytorch_cos_sim(\"\"\"insert code\"\"\", embeddings_current.to(device))\n",
        "\n",
        "    # Store the similarity and sentence in the lists, initialized above to store top similar scores and similar sentences\n",
        "    \"\"\"insert code\"\"\".append(similarity.item())\n",
        "    \"\"\"insert code\"\"\".append(row['text'])\n",
        "\n",
        "# Get the indices of the top x most similar sentences\n",
        "top_indices = sorted(range(len(top_similarities)), key=lambda i: top_similarities[i], reverse=True)[:num_similar_sentences]\n",
        "\n",
        "# Print the user sentence\n",
        "print(f'User sentence: {user_sentence}')\n",
        "\n",
        "# Print the top x most similar sentences\n",
        "print(f'Top {num_similar_sentences} Most Similar Sentences:')\n",
        "for idx in top_indices:\n",
        "    print(f'Sentence: {top_similar_sentences[idx]} - Cosine Similarity: {top_similarities[idx]}')\n"
      ],
      "metadata": {
        "id": "EMOikhVX4wjU"
      },
      "id": "EMOikhVX4wjU",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.4 Your variation on cosine similarity"
      ],
      "metadata": {
        "id": "CDeBmC-3Fvtp"
      },
      "id": "CDeBmC-3Fvtp"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Modify the script above in this way:<br>\n",
        "-instead of specifying the number of most similar sentences, specify a similarity score.<br>\n",
        "-only the pandas frame rows, with a sentence similarity score higher than the user specified score are kept in a list and printed to a new csv file. <br>\n",
        "-if there are no candidates, a message should be printed stating there are no candidates."
      ],
      "metadata": {
        "id": "X9jXeCmyGDiZ"
      },
      "id": "X9jXeCmyGDiZ"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}